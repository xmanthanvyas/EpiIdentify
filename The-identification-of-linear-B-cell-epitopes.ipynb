{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57f1f267",
   "metadata": {},
   "source": [
    "Linear B-cell epitope detection\n",
    "\n",
    "Problem Introduction:\n",
    "\n",
    "The development of vaccines, diagnostic tools, and therapeutic interventions against a variety of illnesses, including infectious diseases, allergies, and some malignancies, depends on the identification of linear B-cell epitopes. However, the experimental search for these epitopes can be time and resource-consuming. Therefore, during the past few decades, computational techniques have been developed to assist in the prioritisation of possible epitopes for additional characterisation in the laboratory. The effectiveness of this process has significantly increased because of recent developments in computer techniques, making it more convenient and economical. This issue statement emphasises the significance of identifying linear B-cell epitopes, the difficulties in their experimental identification, and the possible advantages of computational techniques for quickening this process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eef3d9d",
   "metadata": {},
   "source": [
    "Data Overview:\n",
    "\n",
    "The information relates to the epitope prediction for the Alphavirus family of mosquito-borne viruses, which includes the Chikungunya virus and other viruses that infect millions of people worldwide. Using research tools produced by the team at Aston University, the dataset was created by parsing and combining information received from three internet databases, namely IEDB, Genbank, and UniProtKB. To forecast brand-new, previously unidentified epitopes in viruses from the Alphavirus genus, I need to create an efficient data mining pipeline. The dataset contains details on host organisms, epitope sites, amino acid sequences, and other pertinent metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1025bb",
   "metadata": {},
   "source": [
    "The following Python packages have been utilized during various stages of the project.\n",
    "\n",
    "NumPy: NumPy is a Python library used for scientific computing. It provides a powerful N-dimensional array object, as well as functions for performing mathematical operations on arrays.\n",
    "\n",
    "Pandas: Pandas is a Python library that provides data structures for efficiently storing and manipulating large datasets.\n",
    "\n",
    "Matplotlib: Matplotlib is a Python library used for creating static, animated, and interactive visualizations in Python.\n",
    "\n",
    "The sklearn.model_selection module in scikit-learn provides various tools for model selection and evaluation, including functions for splitting datasets into training and testing sets. \n",
    "\n",
    "Boruta: Boruta is a feature selection library in Python that is used to select relevant features in a dataset for a given machine learning task.\n",
    "\n",
    "RandomForestClassifier: RandomForestClassifier is a classification algorithm in scikit-learn that uses an ensemble of decision trees to classify data.\n",
    "\n",
    "The imblearn.over_sampling module in imbalanced-learn provides various techniques for oversampling the minority class in imbalanced datasets.\n",
    "\n",
    "sklearn.metrics: This is a package in scikit-learn that contains various metrics for evaluating the performance of machine learning models.\n",
    "\n",
    "sklearn.model_selection: This is a package in scikit-learn that provides various tools for model selection and evaluation.\n",
    "\n",
    "sklearn.pipeline: This is a package in scikit-learn that provides tools for constructing machine learning pipelines, which are a way to organize multiple steps in a machine learning workflow.\n",
    "\n",
    "sklearn.preprocessing: This is a package in scikit-learn that provides various tools for preprocessing data before feeding it into a machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0668c4",
   "metadata": {},
   "source": [
    "## df_training_level1(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97248441",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb500615",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis and Pre-processing\n",
    "\n",
    "EDA is the process of analyzing and understanding data to summarize its main characteristics and detect patterns, relationships, and anomalies. The goal of pre-processing is to ensure that the data is in a suitable format for analysis, and to reduce noise and bias that could affect the accuracy and generalizability of the results. Pre-processing steps can include handling missing data, dealing with outliers, scaling and normalizing data, encoding categorical variables, and feature engineering, among others.\n",
    "\n",
    "Data Load:\n",
    "\n",
    "This line of the below code reads a CSV file called \"df_training_level1(1).csv\" into a pandas DataFrame object called \"df\". read_csv() is a function in pandas that reads a CSV file and returns a DataFrame object containing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee6c2ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('df_training_level1(1).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f80f73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Info_PepID</th>\n",
       "      <th>Info_organism_id</th>\n",
       "      <th>Info_protein_id</th>\n",
       "      <th>Info_pos</th>\n",
       "      <th>Info_AA</th>\n",
       "      <th>Info_pubmed_id</th>\n",
       "      <th>Info_epitope_id</th>\n",
       "      <th>Info_host_id</th>\n",
       "      <th>Info_nPos</th>\n",
       "      <th>Info_nNeg</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_esm1b_1270</th>\n",
       "      <th>feat_esm1b_1271</th>\n",
       "      <th>feat_esm1b_1272</th>\n",
       "      <th>feat_esm1b_1273</th>\n",
       "      <th>feat_esm1b_1274</th>\n",
       "      <th>feat_esm1b_1275</th>\n",
       "      <th>feat_esm1b_1276</th>\n",
       "      <th>feat_esm1b_1277</th>\n",
       "      <th>feat_esm1b_1278</th>\n",
       "      <th>feat_esm1b_1279</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAA51871.1:2</td>\n",
       "      <td>12161</td>\n",
       "      <td>CAA51871.1</td>\n",
       "      <td>685</td>\n",
       "      <td>S</td>\n",
       "      <td>11458006</td>\n",
       "      <td>60725</td>\n",
       "      <td>10000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178513</td>\n",
       "      <td>-0.257270</td>\n",
       "      <td>-0.153925</td>\n",
       "      <td>0.014767</td>\n",
       "      <td>-1.294921</td>\n",
       "      <td>-0.112832</td>\n",
       "      <td>0.260342</td>\n",
       "      <td>0.123651</td>\n",
       "      <td>0.159365</td>\n",
       "      <td>0.172829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAA51871.1:2</td>\n",
       "      <td>12161</td>\n",
       "      <td>CAA51871.1</td>\n",
       "      <td>686</td>\n",
       "      <td>R</td>\n",
       "      <td>11458006</td>\n",
       "      <td>60725</td>\n",
       "      <td>10000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.539347</td>\n",
       "      <td>-0.173580</td>\n",
       "      <td>-0.122266</td>\n",
       "      <td>0.235858</td>\n",
       "      <td>-1.230598</td>\n",
       "      <td>-0.060592</td>\n",
       "      <td>0.160817</td>\n",
       "      <td>0.310983</td>\n",
       "      <td>0.146951</td>\n",
       "      <td>0.240393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAA51871.1:2</td>\n",
       "      <td>12161</td>\n",
       "      <td>CAA51871.1</td>\n",
       "      <td>687</td>\n",
       "      <td>L</td>\n",
       "      <td>11458006</td>\n",
       "      <td>60725</td>\n",
       "      <td>10000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.224537</td>\n",
       "      <td>-0.165938</td>\n",
       "      <td>-0.125078</td>\n",
       "      <td>0.131652</td>\n",
       "      <td>-1.359426</td>\n",
       "      <td>0.020718</td>\n",
       "      <td>0.160984</td>\n",
       "      <td>0.189219</td>\n",
       "      <td>0.204018</td>\n",
       "      <td>0.336321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAA51871.1:2</td>\n",
       "      <td>12161</td>\n",
       "      <td>CAA51871.1</td>\n",
       "      <td>688</td>\n",
       "      <td>L</td>\n",
       "      <td>11458006</td>\n",
       "      <td>60725</td>\n",
       "      <td>10000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173186</td>\n",
       "      <td>-0.069608</td>\n",
       "      <td>-0.133053</td>\n",
       "      <td>0.043285</td>\n",
       "      <td>-1.559416</td>\n",
       "      <td>-0.032758</td>\n",
       "      <td>0.099643</td>\n",
       "      <td>0.117604</td>\n",
       "      <td>0.112384</td>\n",
       "      <td>0.367813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAA51871.1:2</td>\n",
       "      <td>12161</td>\n",
       "      <td>CAA51871.1</td>\n",
       "      <td>689</td>\n",
       "      <td>E</td>\n",
       "      <td>11458006</td>\n",
       "      <td>60725</td>\n",
       "      <td>10000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136331</td>\n",
       "      <td>-0.068715</td>\n",
       "      <td>0.032138</td>\n",
       "      <td>0.099051</td>\n",
       "      <td>-1.643639</td>\n",
       "      <td>-0.199724</td>\n",
       "      <td>0.076023</td>\n",
       "      <td>-0.128873</td>\n",
       "      <td>0.127291</td>\n",
       "      <td>0.278798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1294 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Info_PepID  Info_organism_id Info_protein_id  Info_pos Info_AA  \\\n",
       "0  CAA51871.1:2             12161      CAA51871.1       685       S   \n",
       "1  CAA51871.1:2             12161      CAA51871.1       686       R   \n",
       "2  CAA51871.1:2             12161      CAA51871.1       687       L   \n",
       "3  CAA51871.1:2             12161      CAA51871.1       688       L   \n",
       "4  CAA51871.1:2             12161      CAA51871.1       689       E   \n",
       "\n",
       "  Info_pubmed_id Info_epitope_id Info_host_id Info_nPos Info_nNeg  ...  \\\n",
       "0       11458006           60725     10000000         2         0  ...   \n",
       "1       11458006           60725     10000000         2         0  ...   \n",
       "2       11458006           60725     10000000         2         0  ...   \n",
       "3       11458006           60725     10000000         2         0  ...   \n",
       "4       11458006           60725     10000000         2         0  ...   \n",
       "\n",
       "  feat_esm1b_1270 feat_esm1b_1271  feat_esm1b_1272  feat_esm1b_1273  \\\n",
       "0        0.178513       -0.257270        -0.153925         0.014767   \n",
       "1        0.539347       -0.173580        -0.122266         0.235858   \n",
       "2        0.224537       -0.165938        -0.125078         0.131652   \n",
       "3        0.173186       -0.069608        -0.133053         0.043285   \n",
       "4        0.136331       -0.068715         0.032138         0.099051   \n",
       "\n",
       "   feat_esm1b_1274  feat_esm1b_1275  feat_esm1b_1276  feat_esm1b_1277  \\\n",
       "0        -1.294921        -0.112832         0.260342         0.123651   \n",
       "1        -1.230598        -0.060592         0.160817         0.310983   \n",
       "2        -1.359426         0.020718         0.160984         0.189219   \n",
       "3        -1.559416        -0.032758         0.099643         0.117604   \n",
       "4        -1.643639        -0.199724         0.076023        -0.128873   \n",
       "\n",
       "   feat_esm1b_1278  feat_esm1b_1279  \n",
       "0         0.159365         0.172829  \n",
       "1         0.146951         0.240393  \n",
       "2         0.204018         0.336321  \n",
       "3         0.112384         0.367813  \n",
       "4         0.127291         0.278798  \n",
       "\n",
       "[5 rows x 1294 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c55349a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(746, 1294)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec8c95c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204    516\n",
       "298     69\n",
       "229     54\n",
       "320     42\n",
       "199     30\n",
       "215     20\n",
       "264      8\n",
       "256      7\n",
       "Name: Info_cluster, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Info_cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae55902c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['Info_cluster'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2186a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df.copy()  # Make a copy of the original dataframe\n",
    "df = df.drop(columns=df.filter(regex='^Info_'))  # Drop columns starting with 'Info_'\n",
    "df['Info_cluster'] = df_temp['Info_cluster'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcb0c862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 746 entries, 0 to 745\n",
      "Columns: 1282 entries, Class to Info_cluster\n",
      "dtypes: float64(1280), int64(2)\n",
      "memory usage: 7.3 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ab0804",
   "metadata": {},
   "source": [
    "Data Cleaning\n",
    "\n",
    "Remove invalid observations in the data:\n",
    "\n",
    "Data cleaning involves removing inaccurate observations from a dataset. Data points with missing, inaccurate, or inconsistent values are frequently considered invalid observations since they cannot be used for analysis. There may be columns in many datasets that provide broad details about the observations but are not specifically pertinent to the desired prediction or analysis. In this instance, these columns are known as metadata or descriptive data and their names begin with \"Info_\". Because they lack any significant predictive value, metadata and descriptive data are typically not helpful for modelling and prediction. Instead, they offer background and more details about the dataset's observations. The source of the data, the date it was obtained, or demographic details about the participants are a few examples of metadata columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cf1b5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0472ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of outlier records: 3058\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(columns='Info_cluster')\n",
    "\n",
    "# Identify outliers using z-scores\n",
    "z_scores = (df - df.mean()) / df.std()  # Calculate z-scores for each value in the dataframe\n",
    "outliers = np.abs(z_scores) > 3  # Set threshold for outlier detection at 3 standard deviations from the mean\n",
    "n_outliers = outliers.sum().sum()  # Count total number of True values in the dataframe\n",
    "\n",
    "# Print the total number of outlier records\n",
    "print(\"Total number of outlier records:\", n_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2822c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>feat_esm1b_0</th>\n",
       "      <th>feat_esm1b_1</th>\n",
       "      <th>feat_esm1b_2</th>\n",
       "      <th>feat_esm1b_3</th>\n",
       "      <th>feat_esm1b_4</th>\n",
       "      <th>feat_esm1b_5</th>\n",
       "      <th>feat_esm1b_6</th>\n",
       "      <th>feat_esm1b_7</th>\n",
       "      <th>feat_esm1b_8</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_esm1b_1270</th>\n",
       "      <th>feat_esm1b_1271</th>\n",
       "      <th>feat_esm1b_1272</th>\n",
       "      <th>feat_esm1b_1273</th>\n",
       "      <th>feat_esm1b_1274</th>\n",
       "      <th>feat_esm1b_1275</th>\n",
       "      <th>feat_esm1b_1276</th>\n",
       "      <th>feat_esm1b_1277</th>\n",
       "      <th>feat_esm1b_1278</th>\n",
       "      <th>feat_esm1b_1279</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>746.000000</td>\n",
       "      <td>746.000000</td>\n",
       "      <td>746.000000</td>\n",
       "      <td>746.000000</td>\n",
       "      <td>746.000000</td>\n",
       "      <td>746.000000</td>\n",
       "      <td>746.000000</td>\n",
       "      <td>746.000000</td>\n",
       "      <td>746.000000</td>\n",
       "      <td>746.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>746.000000</td>\n",
       "      <td>746.000000</td>\n",
       "      <td>746.000000</td>\n",
       "      <td>746.000000</td>\n",
       "      <td>746.000000</td>\n",
       "      <td>746.000000</td>\n",
       "      <td>746.000000</td>\n",
       "      <td>746.000000</td>\n",
       "      <td>746.000000</td>\n",
       "      <td>746.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.225201</td>\n",
       "      <td>0.081334</td>\n",
       "      <td>0.155190</td>\n",
       "      <td>0.045183</td>\n",
       "      <td>0.093532</td>\n",
       "      <td>-0.187883</td>\n",
       "      <td>-0.079048</td>\n",
       "      <td>0.002961</td>\n",
       "      <td>-0.013465</td>\n",
       "      <td>-0.093546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082458</td>\n",
       "      <td>-0.026580</td>\n",
       "      <td>-0.052922</td>\n",
       "      <td>0.130508</td>\n",
       "      <td>-0.912585</td>\n",
       "      <td>-0.068948</td>\n",
       "      <td>0.098828</td>\n",
       "      <td>-0.005770</td>\n",
       "      <td>0.026254</td>\n",
       "      <td>0.234138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.974966</td>\n",
       "      <td>0.134752</td>\n",
       "      <td>0.135894</td>\n",
       "      <td>0.153447</td>\n",
       "      <td>0.126711</td>\n",
       "      <td>0.150018</td>\n",
       "      <td>0.171420</td>\n",
       "      <td>0.171293</td>\n",
       "      <td>0.189475</td>\n",
       "      <td>0.146342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149778</td>\n",
       "      <td>0.133427</td>\n",
       "      <td>0.138832</td>\n",
       "      <td>0.141839</td>\n",
       "      <td>0.326053</td>\n",
       "      <td>0.151345</td>\n",
       "      <td>0.151581</td>\n",
       "      <td>0.145622</td>\n",
       "      <td>0.148122</td>\n",
       "      <td>0.159960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.605968</td>\n",
       "      <td>-0.368321</td>\n",
       "      <td>-0.453714</td>\n",
       "      <td>-0.270026</td>\n",
       "      <td>-0.623107</td>\n",
       "      <td>-0.587313</td>\n",
       "      <td>-0.546888</td>\n",
       "      <td>-0.428600</td>\n",
       "      <td>-0.537224</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.252364</td>\n",
       "      <td>-0.426012</td>\n",
       "      <td>-0.438437</td>\n",
       "      <td>-0.298351</td>\n",
       "      <td>-1.749543</td>\n",
       "      <td>-0.402438</td>\n",
       "      <td>-0.344357</td>\n",
       "      <td>-0.456177</td>\n",
       "      <td>-0.401215</td>\n",
       "      <td>-0.326890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.005342</td>\n",
       "      <td>0.056017</td>\n",
       "      <td>-0.045173</td>\n",
       "      <td>0.007387</td>\n",
       "      <td>-0.283482</td>\n",
       "      <td>-0.200325</td>\n",
       "      <td>-0.115509</td>\n",
       "      <td>-0.157970</td>\n",
       "      <td>-0.188088</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025213</td>\n",
       "      <td>-0.118891</td>\n",
       "      <td>-0.141919</td>\n",
       "      <td>0.036957</td>\n",
       "      <td>-1.142586</td>\n",
       "      <td>-0.176104</td>\n",
       "      <td>0.003478</td>\n",
       "      <td>-0.091283</td>\n",
       "      <td>-0.083311</td>\n",
       "      <td>0.135777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.093366</td>\n",
       "      <td>0.159134</td>\n",
       "      <td>0.050690</td>\n",
       "      <td>0.102058</td>\n",
       "      <td>-0.190992</td>\n",
       "      <td>-0.087125</td>\n",
       "      <td>-0.000722</td>\n",
       "      <td>-0.023049</td>\n",
       "      <td>-0.095882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070693</td>\n",
       "      <td>-0.026712</td>\n",
       "      <td>-0.052635</td>\n",
       "      <td>0.129109</td>\n",
       "      <td>-0.929380</td>\n",
       "      <td>-0.082213</td>\n",
       "      <td>0.099465</td>\n",
       "      <td>0.008209</td>\n",
       "      <td>0.022796</td>\n",
       "      <td>0.249037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.177607</td>\n",
       "      <td>0.248278</td>\n",
       "      <td>0.140758</td>\n",
       "      <td>0.177299</td>\n",
       "      <td>-0.090165</td>\n",
       "      <td>0.035861</td>\n",
       "      <td>0.120766</td>\n",
       "      <td>0.114863</td>\n",
       "      <td>0.006965</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179583</td>\n",
       "      <td>0.066112</td>\n",
       "      <td>0.049650</td>\n",
       "      <td>0.223102</td>\n",
       "      <td>-0.693119</td>\n",
       "      <td>0.009155</td>\n",
       "      <td>0.192338</td>\n",
       "      <td>0.099157</td>\n",
       "      <td>0.125548</td>\n",
       "      <td>0.340555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.431492</td>\n",
       "      <td>0.533593</td>\n",
       "      <td>0.464730</td>\n",
       "      <td>0.484326</td>\n",
       "      <td>0.291663</td>\n",
       "      <td>0.476413</td>\n",
       "      <td>0.527441</td>\n",
       "      <td>0.568731</td>\n",
       "      <td>0.384280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.546722</td>\n",
       "      <td>0.349790</td>\n",
       "      <td>0.337160</td>\n",
       "      <td>0.576059</td>\n",
       "      <td>0.692667</td>\n",
       "      <td>0.447825</td>\n",
       "      <td>0.676943</td>\n",
       "      <td>0.343372</td>\n",
       "      <td>0.521267</td>\n",
       "      <td>0.624794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 1281 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Class  feat_esm1b_0  feat_esm1b_1  feat_esm1b_2  feat_esm1b_3  \\\n",
       "count  746.000000    746.000000    746.000000    746.000000    746.000000   \n",
       "mean     0.225201      0.081334      0.155190      0.045183      0.093532   \n",
       "std      0.974966      0.134752      0.135894      0.153447      0.126711   \n",
       "min     -1.000000     -0.605968     -0.368321     -0.453714     -0.270026   \n",
       "25%     -1.000000     -0.005342      0.056017     -0.045173      0.007387   \n",
       "50%      1.000000      0.093366      0.159134      0.050690      0.102058   \n",
       "75%      1.000000      0.177607      0.248278      0.140758      0.177299   \n",
       "max      1.000000      0.431492      0.533593      0.464730      0.484326   \n",
       "\n",
       "       feat_esm1b_4  feat_esm1b_5  feat_esm1b_6  feat_esm1b_7  feat_esm1b_8  \\\n",
       "count    746.000000    746.000000    746.000000    746.000000    746.000000   \n",
       "mean      -0.187883     -0.079048      0.002961     -0.013465     -0.093546   \n",
       "std        0.150018      0.171420      0.171293      0.189475      0.146342   \n",
       "min       -0.623107     -0.587313     -0.546888     -0.428600     -0.537224   \n",
       "25%       -0.283482     -0.200325     -0.115509     -0.157970     -0.188088   \n",
       "50%       -0.190992     -0.087125     -0.000722     -0.023049     -0.095882   \n",
       "75%       -0.090165      0.035861      0.120766      0.114863      0.006965   \n",
       "max        0.291663      0.476413      0.527441      0.568731      0.384280   \n",
       "\n",
       "       ...  feat_esm1b_1270  feat_esm1b_1271  feat_esm1b_1272  \\\n",
       "count  ...       746.000000       746.000000       746.000000   \n",
       "mean   ...         0.082458        -0.026580        -0.052922   \n",
       "std    ...         0.149778         0.133427         0.138832   \n",
       "min    ...        -0.252364        -0.426012        -0.438437   \n",
       "25%    ...        -0.025213        -0.118891        -0.141919   \n",
       "50%    ...         0.070693        -0.026712        -0.052635   \n",
       "75%    ...         0.179583         0.066112         0.049650   \n",
       "max    ...         0.546722         0.349790         0.337160   \n",
       "\n",
       "       feat_esm1b_1273  feat_esm1b_1274  feat_esm1b_1275  feat_esm1b_1276  \\\n",
       "count       746.000000       746.000000       746.000000       746.000000   \n",
       "mean          0.130508        -0.912585        -0.068948         0.098828   \n",
       "std           0.141839         0.326053         0.151345         0.151581   \n",
       "min          -0.298351        -1.749543        -0.402438        -0.344357   \n",
       "25%           0.036957        -1.142586        -0.176104         0.003478   \n",
       "50%           0.129109        -0.929380        -0.082213         0.099465   \n",
       "75%           0.223102        -0.693119         0.009155         0.192338   \n",
       "max           0.576059         0.692667         0.447825         0.676943   \n",
       "\n",
       "       feat_esm1b_1277  feat_esm1b_1278  feat_esm1b_1279  \n",
       "count       746.000000       746.000000       746.000000  \n",
       "mean         -0.005770         0.026254         0.234138  \n",
       "std           0.145622         0.148122         0.159960  \n",
       "min          -0.456177        -0.401215        -0.326890  \n",
       "25%          -0.091283        -0.083311         0.135777  \n",
       "50%           0.008209         0.022796         0.249037  \n",
       "75%           0.099157         0.125548         0.340555  \n",
       "max           0.343372         0.521267         0.624794  \n",
       "\n",
       "[8 rows x 1281 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bbcc173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    457\n",
       "-1    289\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da08eb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deaf005",
   "metadata": {},
   "source": [
    "The below code block is performing outlier detection and removal in the clean_df DataFrame.\n",
    "\n",
    "Next, a threshold of 3 standard deviations from the mean is set as the threshold for outlier detection. Any value in the DataFrame that has a z-score above this threshold is considered an outlier.\n",
    "\n",
    "The np.where function is then used to find the indices of all the data points that have z-scores above the threshold.\n",
    "\n",
    "Finally, the clean_df DataFrame is updated to remove any rows that contain an outlier.\n",
    "\n",
    "Overall, the below code block is performing a common data cleaning step to remove outliers from a DataFrame that may negatively impact the analysis or modeling results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16db8072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate z-scores for each value in the dataframe\n",
    "z_scores = (clean_df - clean_df.mean()) / clean_df.std()\n",
    "\n",
    "# Set threshold for outlier detection at 3 standard deviations from the mean\n",
    "threshold = 3\n",
    "\n",
    "# Find the indices of all data points with z-scores above the threshold\n",
    "outlier_indices = np.where(np.abs(z_scores) > threshold)\n",
    "\n",
    "# Remove the rows with outlier indices\n",
    "clean_df = clean_df[(z_scores <= threshold).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06c7f33c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(286, 1281)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61c3a659",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['Info_cluster'] = df_temp['Info_cluster']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b986979e",
   "metadata": {},
   "source": [
    "The features dataframe is created by selecting all columns of the clean_df dataframe except for the 'Class' column. This is because 'Class' is the target variable that we are trying to predict, so we want to separate it from the other variables to be used as the target during model training.\n",
    "\n",
    "The target series is created by selecting only the 'Class' column from the clean_df dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31f19673",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create a dataframe of features by selecting all columns except for 'Class'\n",
    "features = clean_df.iloc[:, clean_df.columns != 'Class']\n",
    "\n",
    "# Create a series of the target variable ('Class')\n",
    "target = clean_df['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439afc30",
   "metadata": {},
   "source": [
    "In the code below, the train_test_split function from the sklearn.model_selection package is being used to split the dataset into two sets: a training set and a testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b02b4543",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d62861f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['Class'] = clean_df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b2011cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    134\n",
       "-1     94\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbc8de77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from boruta import BorutaPy\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe77e9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_clean = X_train.drop(['Class', 'Info_cluster'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a15c85a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_esm1b_0</th>\n",
       "      <th>feat_esm1b_1</th>\n",
       "      <th>feat_esm1b_2</th>\n",
       "      <th>feat_esm1b_3</th>\n",
       "      <th>feat_esm1b_4</th>\n",
       "      <th>feat_esm1b_5</th>\n",
       "      <th>feat_esm1b_6</th>\n",
       "      <th>feat_esm1b_7</th>\n",
       "      <th>feat_esm1b_8</th>\n",
       "      <th>feat_esm1b_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_esm1b_1270</th>\n",
       "      <th>feat_esm1b_1271</th>\n",
       "      <th>feat_esm1b_1272</th>\n",
       "      <th>feat_esm1b_1273</th>\n",
       "      <th>feat_esm1b_1274</th>\n",
       "      <th>feat_esm1b_1275</th>\n",
       "      <th>feat_esm1b_1276</th>\n",
       "      <th>feat_esm1b_1277</th>\n",
       "      <th>feat_esm1b_1278</th>\n",
       "      <th>feat_esm1b_1279</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>0.233186</td>\n",
       "      <td>0.205879</td>\n",
       "      <td>0.087787</td>\n",
       "      <td>0.010214</td>\n",
       "      <td>-0.288821</td>\n",
       "      <td>-0.139800</td>\n",
       "      <td>0.007510</td>\n",
       "      <td>0.086230</td>\n",
       "      <td>-0.085637</td>\n",
       "      <td>0.147678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051967</td>\n",
       "      <td>0.007124</td>\n",
       "      <td>-0.034588</td>\n",
       "      <td>0.168150</td>\n",
       "      <td>-1.130909</td>\n",
       "      <td>-0.116927</td>\n",
       "      <td>0.127482</td>\n",
       "      <td>0.093444</td>\n",
       "      <td>0.058868</td>\n",
       "      <td>0.360519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.055757</td>\n",
       "      <td>0.369110</td>\n",
       "      <td>-0.060843</td>\n",
       "      <td>0.241634</td>\n",
       "      <td>-0.204576</td>\n",
       "      <td>-0.343872</td>\n",
       "      <td>0.196596</td>\n",
       "      <td>0.191587</td>\n",
       "      <td>0.032379</td>\n",
       "      <td>0.039993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049512</td>\n",
       "      <td>0.015279</td>\n",
       "      <td>0.085996</td>\n",
       "      <td>0.253194</td>\n",
       "      <td>-1.096287</td>\n",
       "      <td>-0.206165</td>\n",
       "      <td>0.046195</td>\n",
       "      <td>0.120146</td>\n",
       "      <td>0.022065</td>\n",
       "      <td>0.432276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>-0.057328</td>\n",
       "      <td>0.232387</td>\n",
       "      <td>0.351349</td>\n",
       "      <td>0.297257</td>\n",
       "      <td>-0.324487</td>\n",
       "      <td>-0.052465</td>\n",
       "      <td>0.109125</td>\n",
       "      <td>-0.099163</td>\n",
       "      <td>-0.013503</td>\n",
       "      <td>0.163332</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026349</td>\n",
       "      <td>-0.228668</td>\n",
       "      <td>-0.111712</td>\n",
       "      <td>0.115414</td>\n",
       "      <td>-1.054878</td>\n",
       "      <td>-0.332554</td>\n",
       "      <td>0.187835</td>\n",
       "      <td>-0.002159</td>\n",
       "      <td>0.286191</td>\n",
       "      <td>0.326535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0.077823</td>\n",
       "      <td>0.244874</td>\n",
       "      <td>0.038710</td>\n",
       "      <td>0.174485</td>\n",
       "      <td>-0.147916</td>\n",
       "      <td>-0.092489</td>\n",
       "      <td>0.139395</td>\n",
       "      <td>0.016404</td>\n",
       "      <td>-0.046938</td>\n",
       "      <td>-0.109215</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.164557</td>\n",
       "      <td>0.042635</td>\n",
       "      <td>-0.045513</td>\n",
       "      <td>0.185466</td>\n",
       "      <td>-0.742485</td>\n",
       "      <td>-0.246150</td>\n",
       "      <td>0.204462</td>\n",
       "      <td>0.168001</td>\n",
       "      <td>-0.069805</td>\n",
       "      <td>0.331076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.145469</td>\n",
       "      <td>0.083274</td>\n",
       "      <td>0.187002</td>\n",
       "      <td>-0.019862</td>\n",
       "      <td>-0.279790</td>\n",
       "      <td>-0.093475</td>\n",
       "      <td>0.042988</td>\n",
       "      <td>-0.004669</td>\n",
       "      <td>-0.107092</td>\n",
       "      <td>0.059543</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.228307</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.018809</td>\n",
       "      <td>0.298190</td>\n",
       "      <td>-1.241184</td>\n",
       "      <td>-0.221347</td>\n",
       "      <td>-0.025244</td>\n",
       "      <td>-0.247902</td>\n",
       "      <td>-0.111732</td>\n",
       "      <td>0.160511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1280 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feat_esm1b_0  feat_esm1b_1  feat_esm1b_2  feat_esm1b_3  feat_esm1b_4  \\\n",
       "244      0.233186      0.205879      0.087787      0.010214     -0.288821   \n",
       "61       0.055757      0.369110     -0.060843      0.241634     -0.204576   \n",
       "163     -0.057328      0.232387      0.351349      0.297257     -0.324487   \n",
       "249      0.077823      0.244874      0.038710      0.174485     -0.147916   \n",
       "116      0.145469      0.083274      0.187002     -0.019862     -0.279790   \n",
       "\n",
       "     feat_esm1b_5  feat_esm1b_6  feat_esm1b_7  feat_esm1b_8  feat_esm1b_9  \\\n",
       "244     -0.139800      0.007510      0.086230     -0.085637      0.147678   \n",
       "61      -0.343872      0.196596      0.191587      0.032379      0.039993   \n",
       "163     -0.052465      0.109125     -0.099163     -0.013503      0.163332   \n",
       "249     -0.092489      0.139395      0.016404     -0.046938     -0.109215   \n",
       "116     -0.093475      0.042988     -0.004669     -0.107092      0.059543   \n",
       "\n",
       "     ...  feat_esm1b_1270  feat_esm1b_1271  feat_esm1b_1272  feat_esm1b_1273  \\\n",
       "244  ...         0.051967         0.007124        -0.034588         0.168150   \n",
       "61   ...         0.049512         0.015279         0.085996         0.253194   \n",
       "163  ...        -0.026349        -0.228668        -0.111712         0.115414   \n",
       "249  ...        -0.164557         0.042635        -0.045513         0.185466   \n",
       "116  ...        -0.228307         0.027000         0.018809         0.298190   \n",
       "\n",
       "     feat_esm1b_1274  feat_esm1b_1275  feat_esm1b_1276  feat_esm1b_1277  \\\n",
       "244        -1.130909        -0.116927         0.127482         0.093444   \n",
       "61         -1.096287        -0.206165         0.046195         0.120146   \n",
       "163        -1.054878        -0.332554         0.187835        -0.002159   \n",
       "249        -0.742485        -0.246150         0.204462         0.168001   \n",
       "116        -1.241184        -0.221347        -0.025244        -0.247902   \n",
       "\n",
       "     feat_esm1b_1278  feat_esm1b_1279  \n",
       "244         0.058868         0.360519  \n",
       "61          0.022065         0.432276  \n",
       "163         0.286191         0.326535  \n",
       "249        -0.069805         0.331076  \n",
       "116        -0.111732         0.160511  \n",
       "\n",
       "[5 rows x 1280 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "795c006a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((228, 1280), (228,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_clean.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5de9660f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t1 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t1280\n",
      "Rejected: \t0\n",
      "Iteration: \t2 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t1280\n",
      "Rejected: \t0\n",
      "Iteration: \t3 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t1280\n",
      "Rejected: \t0\n",
      "Iteration: \t4 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t1280\n",
      "Rejected: \t0\n",
      "Iteration: \t5 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t1280\n",
      "Rejected: \t0\n",
      "Iteration: \t6 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t1280\n",
      "Rejected: \t0\n",
      "Iteration: \t7 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t1280\n",
      "Rejected: \t0\n",
      "Iteration: \t8 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t1280\n",
      "Rejected: \t0\n",
      "Iteration: \t9 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t1280\n",
      "Rejected: \t0\n",
      "Iteration: \t10 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t1280\n",
      "Rejected: \t0\n",
      "Iteration: \t11 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t1280\n",
      "Rejected: \t0\n",
      "Iteration: \t12 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t1280\n",
      "Rejected: \t0\n",
      "Iteration: \t13 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t1280\n",
      "Rejected: \t0\n",
      "Iteration: \t14 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t1280\n",
      "Rejected: \t0\n",
      "Iteration: \t15 / 100\n",
      "Confirmed: \t8\n",
      "Tentative: \t101\n",
      "Rejected: \t1171\n",
      "Iteration: \t16 / 100\n",
      "Confirmed: \t8\n",
      "Tentative: \t101\n",
      "Rejected: \t1171\n",
      "Iteration: \t17 / 100\n",
      "Confirmed: \t8\n",
      "Tentative: \t101\n",
      "Rejected: \t1171\n",
      "Iteration: \t18 / 100\n",
      "Confirmed: \t8\n",
      "Tentative: \t101\n",
      "Rejected: \t1171\n",
      "Iteration: \t19 / 100\n",
      "Confirmed: \t10\n",
      "Tentative: \t93\n",
      "Rejected: \t1177\n",
      "Iteration: \t20 / 100\n",
      "Confirmed: \t10\n",
      "Tentative: \t93\n",
      "Rejected: \t1177\n",
      "Iteration: \t21 / 100\n",
      "Confirmed: \t10\n",
      "Tentative: \t93\n",
      "Rejected: \t1177\n",
      "Iteration: \t22 / 100\n",
      "Confirmed: \t10\n",
      "Tentative: \t93\n",
      "Rejected: \t1177\n",
      "Iteration: \t23 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t83\n",
      "Rejected: \t1181\n",
      "Iteration: \t24 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t83\n",
      "Rejected: \t1181\n",
      "Iteration: \t25 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t83\n",
      "Rejected: \t1181\n",
      "Iteration: \t26 / 100\n",
      "Confirmed: \t16\n",
      "Tentative: \t83\n",
      "Rejected: \t1181\n",
      "Iteration: \t27 / 100\n",
      "Confirmed: \t19\n",
      "Tentative: \t76\n",
      "Rejected: \t1185\n",
      "Iteration: \t28 / 100\n",
      "Confirmed: \t19\n",
      "Tentative: \t76\n",
      "Rejected: \t1185\n",
      "Iteration: \t29 / 100\n",
      "Confirmed: \t19\n",
      "Tentative: \t76\n",
      "Rejected: \t1185\n",
      "Iteration: \t30 / 100\n",
      "Confirmed: \t22\n",
      "Tentative: \t72\n",
      "Rejected: \t1186\n",
      "Iteration: \t31 / 100\n",
      "Confirmed: \t22\n",
      "Tentative: \t72\n",
      "Rejected: \t1186\n",
      "Iteration: \t32 / 100\n",
      "Confirmed: \t22\n",
      "Tentative: \t72\n",
      "Rejected: \t1186\n",
      "Iteration: \t33 / 100\n",
      "Confirmed: \t23\n",
      "Tentative: \t67\n",
      "Rejected: \t1190\n",
      "Iteration: \t34 / 100\n",
      "Confirmed: \t23\n",
      "Tentative: \t67\n",
      "Rejected: \t1190\n",
      "Iteration: \t35 / 100\n",
      "Confirmed: \t23\n",
      "Tentative: \t67\n",
      "Rejected: \t1190\n",
      "Iteration: \t36 / 100\n",
      "Confirmed: \t23\n",
      "Tentative: \t66\n",
      "Rejected: \t1191\n",
      "Iteration: \t37 / 100\n",
      "Confirmed: \t23\n",
      "Tentative: \t66\n",
      "Rejected: \t1191\n",
      "Iteration: \t38 / 100\n",
      "Confirmed: \t23\n",
      "Tentative: \t66\n",
      "Rejected: \t1191\n",
      "Iteration: \t39 / 100\n",
      "Confirmed: \t23\n",
      "Tentative: \t64\n",
      "Rejected: \t1193\n",
      "Iteration: \t40 / 100\n",
      "Confirmed: \t23\n",
      "Tentative: \t64\n",
      "Rejected: \t1193\n",
      "Iteration: \t41 / 100\n",
      "Confirmed: \t23\n",
      "Tentative: \t64\n",
      "Rejected: \t1193\n",
      "Iteration: \t42 / 100\n",
      "Confirmed: \t23\n",
      "Tentative: \t62\n",
      "Rejected: \t1195\n",
      "Iteration: \t43 / 100\n",
      "Confirmed: \t23\n",
      "Tentative: \t62\n",
      "Rejected: \t1195\n",
      "Iteration: \t44 / 100\n",
      "Confirmed: \t23\n",
      "Tentative: \t62\n",
      "Rejected: \t1195\n",
      "Iteration: \t45 / 100\n",
      "Confirmed: \t23\n",
      "Tentative: \t62\n",
      "Rejected: \t1195\n",
      "Iteration: \t46 / 100\n",
      "Confirmed: \t23\n",
      "Tentative: \t62\n",
      "Rejected: \t1195\n",
      "Iteration: \t47 / 100\n",
      "Confirmed: \t23\n",
      "Tentative: \t62\n",
      "Rejected: \t1195\n",
      "Iteration: \t48 / 100\n",
      "Confirmed: \t25\n",
      "Tentative: \t60\n",
      "Rejected: \t1195\n",
      "Iteration: \t49 / 100\n",
      "Confirmed: \t25\n",
      "Tentative: \t60\n",
      "Rejected: \t1195\n",
      "Iteration: \t50 / 100\n",
      "Confirmed: \t25\n",
      "Tentative: \t60\n",
      "Rejected: \t1195\n",
      "Iteration: \t51 / 100\n",
      "Confirmed: \t26\n",
      "Tentative: \t59\n",
      "Rejected: \t1195\n",
      "Iteration: \t52 / 100\n",
      "Confirmed: \t26\n",
      "Tentative: \t59\n",
      "Rejected: \t1195\n",
      "Iteration: \t53 / 100\n",
      "Confirmed: \t26\n",
      "Tentative: \t59\n",
      "Rejected: \t1195\n",
      "Iteration: \t54 / 100\n",
      "Confirmed: \t26\n",
      "Tentative: \t59\n",
      "Rejected: \t1195\n",
      "Iteration: \t55 / 100\n",
      "Confirmed: \t26\n",
      "Tentative: \t59\n",
      "Rejected: \t1195\n",
      "Iteration: \t56 / 100\n",
      "Confirmed: \t26\n",
      "Tentative: \t59\n",
      "Rejected: \t1195\n",
      "Iteration: \t57 / 100\n",
      "Confirmed: \t26\n",
      "Tentative: \t59\n",
      "Rejected: \t1195\n",
      "Iteration: \t58 / 100\n",
      "Confirmed: \t26\n",
      "Tentative: \t59\n",
      "Rejected: \t1195\n",
      "Iteration: \t59 / 100\n",
      "Confirmed: \t26\n",
      "Tentative: \t59\n",
      "Rejected: \t1195\n",
      "Iteration: \t60 / 100\n",
      "Confirmed: \t26\n",
      "Tentative: \t59\n",
      "Rejected: \t1195\n",
      "Iteration: \t61 / 100\n",
      "Confirmed: \t26\n",
      "Tentative: \t59\n",
      "Rejected: \t1195\n",
      "Iteration: \t62 / 100\n",
      "Confirmed: \t27\n",
      "Tentative: \t58\n",
      "Rejected: \t1195\n",
      "Iteration: \t63 / 100\n",
      "Confirmed: \t27\n",
      "Tentative: \t58\n",
      "Rejected: \t1195\n",
      "Iteration: \t64 / 100\n",
      "Confirmed: \t27\n",
      "Tentative: \t58\n",
      "Rejected: \t1195\n",
      "Iteration: \t65 / 100\n",
      "Confirmed: \t27\n",
      "Tentative: \t58\n",
      "Rejected: \t1195\n",
      "Iteration: \t66 / 100\n",
      "Confirmed: \t27\n",
      "Tentative: \t58\n",
      "Rejected: \t1195\n",
      "Iteration: \t67 / 100\n",
      "Confirmed: \t29\n",
      "Tentative: \t56\n",
      "Rejected: \t1195\n",
      "Iteration: \t68 / 100\n",
      "Confirmed: \t29\n",
      "Tentative: \t56\n",
      "Rejected: \t1195\n",
      "Iteration: \t69 / 100\n",
      "Confirmed: \t29\n",
      "Tentative: \t56\n",
      "Rejected: \t1195\n",
      "Iteration: \t70 / 100\n",
      "Confirmed: \t30\n",
      "Tentative: \t55\n",
      "Rejected: \t1195\n",
      "Iteration: \t71 / 100\n",
      "Confirmed: \t30\n",
      "Tentative: \t55\n",
      "Rejected: \t1195\n",
      "Iteration: \t72 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t53\n",
      "Rejected: \t1196\n",
      "Iteration: \t73 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t53\n",
      "Rejected: \t1196\n",
      "Iteration: \t74 / 100\n",
      "Confirmed: \t31\n",
      "Tentative: \t53\n",
      "Rejected: \t1196\n",
      "Iteration: \t75 / 100\n",
      "Confirmed: \t32\n",
      "Tentative: \t52\n",
      "Rejected: \t1196\n",
      "Iteration: \t76 / 100\n",
      "Confirmed: \t32\n",
      "Tentative: \t52\n",
      "Rejected: \t1196\n",
      "Iteration: \t77 / 100\n",
      "Confirmed: \t32\n",
      "Tentative: \t52\n",
      "Rejected: \t1196\n",
      "Iteration: \t78 / 100\n",
      "Confirmed: \t32\n",
      "Tentative: \t51\n",
      "Rejected: \t1197\n",
      "Iteration: \t79 / 100\n",
      "Confirmed: \t32\n",
      "Tentative: \t51\n",
      "Rejected: \t1197\n",
      "Iteration: \t80 / 100\n",
      "Confirmed: \t32\n",
      "Tentative: \t50\n",
      "Rejected: \t1198\n",
      "Iteration: \t81 / 100\n",
      "Confirmed: \t32\n",
      "Tentative: \t50\n",
      "Rejected: \t1198\n",
      "Iteration: \t82 / 100\n",
      "Confirmed: \t32\n",
      "Tentative: \t50\n",
      "Rejected: \t1198\n",
      "Iteration: \t83 / 100\n",
      "Confirmed: \t33\n",
      "Tentative: \t48\n",
      "Rejected: \t1199\n",
      "Iteration: \t84 / 100\n",
      "Confirmed: \t33\n",
      "Tentative: \t48\n",
      "Rejected: \t1199\n",
      "Iteration: \t85 / 100\n",
      "Confirmed: \t34\n",
      "Tentative: \t46\n",
      "Rejected: \t1200\n",
      "Iteration: \t86 / 100\n",
      "Confirmed: \t34\n",
      "Tentative: \t46\n",
      "Rejected: \t1200\n",
      "Iteration: \t87 / 100\n",
      "Confirmed: \t34\n",
      "Tentative: \t46\n",
      "Rejected: \t1200\n",
      "Iteration: \t88 / 100\n",
      "Confirmed: \t34\n",
      "Tentative: \t46\n",
      "Rejected: \t1200\n",
      "Iteration: \t89 / 100\n",
      "Confirmed: \t34\n",
      "Tentative: \t46\n",
      "Rejected: \t1200\n",
      "Iteration: \t90 / 100\n",
      "Confirmed: \t35\n",
      "Tentative: \t45\n",
      "Rejected: \t1200\n",
      "Iteration: \t91 / 100\n",
      "Confirmed: \t35\n",
      "Tentative: \t45\n",
      "Rejected: \t1200\n",
      "Iteration: \t92 / 100\n",
      "Confirmed: \t35\n",
      "Tentative: \t45\n",
      "Rejected: \t1200\n",
      "Iteration: \t93 / 100\n",
      "Confirmed: \t36\n",
      "Tentative: \t44\n",
      "Rejected: \t1200\n",
      "Iteration: \t94 / 100\n",
      "Confirmed: \t36\n",
      "Tentative: \t44\n",
      "Rejected: \t1200\n",
      "Iteration: \t95 / 100\n",
      "Confirmed: \t37\n",
      "Tentative: \t43\n",
      "Rejected: \t1200\n",
      "Iteration: \t96 / 100\n",
      "Confirmed: \t37\n",
      "Tentative: \t43\n",
      "Rejected: \t1200\n",
      "Iteration: \t97 / 100\n",
      "Confirmed: \t37\n",
      "Tentative: \t43\n",
      "Rejected: \t1200\n",
      "Iteration: \t98 / 100\n",
      "Confirmed: \t37\n",
      "Tentative: \t43\n",
      "Rejected: \t1200\n",
      "Iteration: \t99 / 100\n",
      "Confirmed: \t37\n",
      "Tentative: \t43\n",
      "Rejected: \t1200\n",
      "\n",
      "\n",
      "BorutaPy finished running.\n",
      "\n",
      "Iteration: \t100 / 100\n",
      "Confirmed: \t37\n",
      "Tentative: \t22\n",
      "Rejected: \t1200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BorutaPy(estimator=RandomForestClassifier(class_weight='balanced', max_depth=5,\n",
       "                                          n_estimators=252, n_jobs=-1,\n",
       "                                          random_state=RandomState(MT19937) at 0x26E0A135E40),\n",
       "         n_estimators='auto',\n",
       "         random_state=RandomState(MT19937) at 0x26E0A135E40, two_step=False,\n",
       "         verbose=3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random forest classifier\n",
    "rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5)\n",
    "\n",
    "# Create a Boruta feature selector instance\n",
    "boruta_selector = BorutaPy(rf, n_estimators='auto', verbose=3, random_state=1, two_step=False)\n",
    "\n",
    "# Fit the Boruta selector to the training data\n",
    "boruta_selector.fit(X_train_clean.values, y_train.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7192d39",
   "metadata": {},
   "source": [
    "The code below is extracting the number of relevant features that were selected by the Boruta feature selection algorithm. The Boruta feature selection algorithm is a wrapper method that uses a random forest classifier to identify relevant features by comparing their importance to that of randomized shadow features. The output of this code shows the number of features that the algorithm identified as relevant for the prediction task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76a5809d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of relevant features: 37\n"
     ]
    }
   ],
   "source": [
    "n_relevant_features = boruta_selector.n_features_\n",
    "print(\"Number of relevant features:\", n_relevant_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdfdfcb",
   "metadata": {},
   "source": [
    "After performing feature selection using the Boruta algorithm, this code retrieves the names of the selected features from the cleaned training data (X_train_clean). The Boruta algorithm marks the selected features with a True value in the boruta_selector.support_ attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a20bd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['feat_esm1b_24', 'feat_esm1b_52', 'feat_esm1b_56', 'feat_esm1b_61', 'feat_esm1b_90', 'feat_esm1b_93', 'feat_esm1b_233', 'feat_esm1b_244', 'feat_esm1b_280', 'feat_esm1b_306', 'feat_esm1b_316', 'feat_esm1b_336', 'feat_esm1b_369', 'feat_esm1b_398', 'feat_esm1b_430', 'feat_esm1b_437', 'feat_esm1b_440', 'feat_esm1b_480', 'feat_esm1b_646', 'feat_esm1b_647', 'feat_esm1b_667', 'feat_esm1b_693', 'feat_esm1b_792', 'feat_esm1b_802', 'feat_esm1b_829', 'feat_esm1b_865', 'feat_esm1b_922', 'feat_esm1b_943', 'feat_esm1b_969', 'feat_esm1b_984', 'feat_esm1b_1019', 'feat_esm1b_1103', 'feat_esm1b_1125', 'feat_esm1b_1136', 'feat_esm1b_1185', 'feat_esm1b_1222', 'feat_esm1b_1267']\n"
     ]
    }
   ],
   "source": [
    "# get selected features\n",
    "sel_features = X_train_clean.columns[boruta_selector.support_].tolist()\n",
    "\n",
    "# print selected features\n",
    "print(sel_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165d466c",
   "metadata": {},
   "source": [
    "Imports the RandomOverSampler class from the imblearn package, which is used for oversampling the minority class in imbalanced datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f723ebb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "X_train_clean = X_train_clean[sel_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b320f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((228, 37), (228,))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_clean.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf70c178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    134\n",
       "-1     94\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a283371",
   "metadata": {},
   "source": [
    "In the code below, RandomOverSampler is used to perform oversampling on the training data to balance the imbalanced classes. This technique generates synthetic samples for the minority class by randomly duplicating existing samples until both classes have equal representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f04c464",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train_clean, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "53283783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((268, 37), (268,))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_resampled.shape, y_train_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aec47239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resampled_df = pd.concat([X_train_resampled, y_train_resampled], axis=1)\n",
    "\n",
    "#get the count of each class\n",
    "class_counts = resampled_df['Class'].value_counts()\n",
    "\n",
    "#plot a bar graph\n",
    "plt.bar(class_counts.index, class_counts.values)\n",
    "plt.title('Class distribution after oversampling')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "98e3c0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc9b99e",
   "metadata": {},
   "source": [
    "The function scales the features using StandardScaler from sklearn.preprocessing. This is an important pre-processing step that standardizes the data by removing the mean and scaling to unit variance. The function then fits the model on the training data using model.fit and makes predictions on the testing data using model.predict. The function calculates the AUC score using roc_auc_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cb47f6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(features, target, model):\n",
    "    train_data, test_data, train_targets, test_targets = train_test_split(features,\n",
    "                                                        target, \n",
    "                                                        test_size=.2,\n",
    "                                                        random_state=42)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    train_data = scaler.fit_transform(train_data)\n",
    "    test_data = scaler.transform(test_data)\n",
    "    \n",
    "    model.fit(train_data, train_targets)\n",
    "    pred = model.predict(test_data)\n",
    "    auc_score = roc_auc_score(test_targets, pred)\n",
    "    print(f\"AUC score: {auc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6732c6",
   "metadata": {},
   "source": [
    "A decision tree-based algorithm called the RandomForestClassifier, which can do both classification and regression tasks, is part of the pipeline. It scales the data to have a zero mean and unit variance.\n",
    "\n",
    "A parameter grid is defined for the hyperparameters of the random forest classifier, including the number of trees, the maximum depth of the trees, and the criterion for splitting nodes. The GridSearchCV function is then used to search over the parameter grid using 5-fold cross-validation to find the best combination of hyperparameters that maximize the model performance.\n",
    "\n",
    "The training data is oversampled using RandomOverSampler to address the issue of class imbalance. The oversampled data is used to train the model, and the performance is evaluated using the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dc5a3950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('classifier',\n",
       "                                        RandomForestClassifier(random_state=42))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'classifier__bootstrap': [True, False],\n",
       "                         'classifier__criterion': ['gini', 'entropy',\n",
       "                                                   'log_loss'],\n",
       "                         'classifier__max_depth': [10, 20, None],\n",
       "                         'classifier__max_features': ['sqrt', 'log2'],\n",
       "                         'classifier__min_samples_leaf': [1, 2, 4],\n",
       "                         'classifier__min_samples_split': [2, 5, 10],\n",
       "                         'classifier__n_estimators': [100, 200, 500]})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', rf)\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200, 500],\n",
    "    'classifier__max_features': ['sqrt', 'log2'],\n",
    "    'classifier__max_depth': [10, 20, None],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],\n",
    "    'classifier__bootstrap': [True, False],\n",
    "    'classifier__criterion': ['gini', 'entropy', 'log_loss']\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(\n",
    "    pipe, param_grid, cv=5, n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54174b52",
   "metadata": {},
   "source": [
    "For df_training_level2(1):\n",
    "\n",
    "This combination of hyperparameters achieved the highest score of 0.8434 in the GridSearchCV cross-validation. These hyperparameters were selected from a grid of different combinations by evaluating the performance of the model using 5-fold cross-validation. The best combination was selected based on the highest score achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c2099942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'classifier__bootstrap': True, 'classifier__criterion': 'gini', 'classifier__max_depth': 20, 'classifier__max_features': 'log2', 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 100}\n",
      "Best Score: 0.8433962264150944\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0ac17f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e08612a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__bootstrap': True,\n",
       " 'classifier__criterion': 'gini',\n",
       " 'classifier__max_depth': 20,\n",
       " 'classifier__max_features': 'log2',\n",
       " 'classifier__min_samples_leaf': 2,\n",
       " 'classifier__min_samples_split': 5,\n",
       " 'classifier__n_estimators': 100}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41da12f",
   "metadata": {},
   "source": [
    "For df_training_level2(1):\n",
    "\n",
    "the second model with an AUC score of 0.9146 is better than the first model with an AUC score of 0.7816. This is because the AUC score is a measure of how well the model can distinguish between positive and negative samples, with a higher score indicating better performance. Therefore, the second model with a higher AUC score is able to better distinguish between the positive and negative samples, indicating better predictive performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f0864d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score: 0.7816\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=100)\n",
    "evaluate_model(X_train_resampled, y_train_resampled, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "50f1de0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_selected = X_test[sel_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f3d1816b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 37)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "96f62a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcc2950",
   "metadata": {},
   "source": [
    "For df_training_level2(1):\n",
    "\n",
    "The second score is better (0.739655921093443) because it is greater than 0.5. The higher the score, the better the model's ability to distinguish between positive and negative classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "55ddc324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e350df45",
   "metadata": {},
   "source": [
    "## df_training_level2(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7fb08e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d049b695",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('df_training_level2(1).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "61199ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Info_PepID</th>\n",
       "      <th>Info_organism_id</th>\n",
       "      <th>Info_protein_id</th>\n",
       "      <th>Info_pos</th>\n",
       "      <th>Info_AA</th>\n",
       "      <th>Info_pubmed_id</th>\n",
       "      <th>Info_epitope_id</th>\n",
       "      <th>Info_host_id</th>\n",
       "      <th>Info_nPos</th>\n",
       "      <th>Info_nNeg</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_esm1b_1270</th>\n",
       "      <th>feat_esm1b_1271</th>\n",
       "      <th>feat_esm1b_1272</th>\n",
       "      <th>feat_esm1b_1273</th>\n",
       "      <th>feat_esm1b_1274</th>\n",
       "      <th>feat_esm1b_1275</th>\n",
       "      <th>feat_esm1b_1276</th>\n",
       "      <th>feat_esm1b_1277</th>\n",
       "      <th>feat_esm1b_1278</th>\n",
       "      <th>feat_esm1b_1279</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BAA01867.1:2</td>\n",
       "      <td>1678143</td>\n",
       "      <td>BAA01867.1</td>\n",
       "      <td>262</td>\n",
       "      <td>E</td>\n",
       "      <td>10449466</td>\n",
       "      <td>14543</td>\n",
       "      <td>9606</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.070886</td>\n",
       "      <td>-0.017200</td>\n",
       "      <td>-0.117530</td>\n",
       "      <td>-0.007250</td>\n",
       "      <td>-1.071874</td>\n",
       "      <td>-0.519040</td>\n",
       "      <td>-0.308719</td>\n",
       "      <td>-0.281276</td>\n",
       "      <td>-0.256712</td>\n",
       "      <td>0.405690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BAA01867.1:2</td>\n",
       "      <td>1678143</td>\n",
       "      <td>BAA01867.1</td>\n",
       "      <td>263</td>\n",
       "      <td>T</td>\n",
       "      <td>10449466</td>\n",
       "      <td>14543</td>\n",
       "      <td>9606</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220630</td>\n",
       "      <td>-0.210780</td>\n",
       "      <td>-0.021335</td>\n",
       "      <td>0.323588</td>\n",
       "      <td>-0.736865</td>\n",
       "      <td>-0.343829</td>\n",
       "      <td>-0.507386</td>\n",
       "      <td>-0.020137</td>\n",
       "      <td>-0.166644</td>\n",
       "      <td>0.751316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAA01867.1:2</td>\n",
       "      <td>1678143</td>\n",
       "      <td>BAA01867.1</td>\n",
       "      <td>264</td>\n",
       "      <td>S</td>\n",
       "      <td>10449466</td>\n",
       "      <td>14543</td>\n",
       "      <td>9606</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107350</td>\n",
       "      <td>-0.059491</td>\n",
       "      <td>-0.167905</td>\n",
       "      <td>0.257423</td>\n",
       "      <td>-0.930690</td>\n",
       "      <td>-0.271957</td>\n",
       "      <td>-0.133815</td>\n",
       "      <td>0.044392</td>\n",
       "      <td>-0.299376</td>\n",
       "      <td>0.461547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BAA01867.1:2</td>\n",
       "      <td>1678143</td>\n",
       "      <td>BAA01867.1</td>\n",
       "      <td>265</td>\n",
       "      <td>G</td>\n",
       "      <td>10449466</td>\n",
       "      <td>14543</td>\n",
       "      <td>9606</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253621</td>\n",
       "      <td>-0.267090</td>\n",
       "      <td>-0.109026</td>\n",
       "      <td>0.091992</td>\n",
       "      <td>-0.813677</td>\n",
       "      <td>-0.187964</td>\n",
       "      <td>-0.142268</td>\n",
       "      <td>0.091157</td>\n",
       "      <td>-0.436975</td>\n",
       "      <td>0.369129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BAA01867.1:2</td>\n",
       "      <td>1678143</td>\n",
       "      <td>BAA01867.1</td>\n",
       "      <td>266</td>\n",
       "      <td>V</td>\n",
       "      <td>10449466</td>\n",
       "      <td>14543</td>\n",
       "      <td>9606</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027382</td>\n",
       "      <td>0.018629</td>\n",
       "      <td>-0.157104</td>\n",
       "      <td>0.305302</td>\n",
       "      <td>-1.121274</td>\n",
       "      <td>-0.048636</td>\n",
       "      <td>-0.246171</td>\n",
       "      <td>0.147852</td>\n",
       "      <td>-0.299121</td>\n",
       "      <td>0.225209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1294 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Info_PepID  Info_organism_id Info_protein_id  Info_pos Info_AA  \\\n",
       "0  BAA01867.1:2           1678143      BAA01867.1       262       E   \n",
       "1  BAA01867.1:2           1678143      BAA01867.1       263       T   \n",
       "2  BAA01867.1:2           1678143      BAA01867.1       264       S   \n",
       "3  BAA01867.1:2           1678143      BAA01867.1       265       G   \n",
       "4  BAA01867.1:2           1678143      BAA01867.1       266       V   \n",
       "\n",
       "  Info_pubmed_id Info_epitope_id Info_host_id Info_nPos Info_nNeg  ...  \\\n",
       "0       10449466           14543         9606         1         1  ...   \n",
       "1       10449466           14543         9606         1         1  ...   \n",
       "2       10449466           14543         9606         1         1  ...   \n",
       "3       10449466           14543         9606         1         1  ...   \n",
       "4       10449466           14543         9606         1         1  ...   \n",
       "\n",
       "  feat_esm1b_1270 feat_esm1b_1271  feat_esm1b_1272  feat_esm1b_1273  \\\n",
       "0       -0.070886       -0.017200        -0.117530        -0.007250   \n",
       "1        0.220630       -0.210780        -0.021335         0.323588   \n",
       "2        0.107350       -0.059491        -0.167905         0.257423   \n",
       "3        0.253621       -0.267090        -0.109026         0.091992   \n",
       "4        0.027382        0.018629        -0.157104         0.305302   \n",
       "\n",
       "   feat_esm1b_1274  feat_esm1b_1275  feat_esm1b_1276  feat_esm1b_1277  \\\n",
       "0        -1.071874        -0.519040        -0.308719        -0.281276   \n",
       "1        -0.736865        -0.343829        -0.507386        -0.020137   \n",
       "2        -0.930690        -0.271957        -0.133815         0.044392   \n",
       "3        -0.813677        -0.187964        -0.142268         0.091157   \n",
       "4        -1.121274        -0.048636        -0.246171         0.147852   \n",
       "\n",
       "   feat_esm1b_1278  feat_esm1b_1279  \n",
       "0        -0.256712         0.405690  \n",
       "1        -0.166644         0.751316  \n",
       "2        -0.299376         0.461547  \n",
       "3        -0.436975         0.369129  \n",
       "4        -0.299121         0.225209  \n",
       "\n",
       "[5 rows x 1294 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "da74831f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4946, 1294)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ad7d41b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34     1633\n",
       "35     1623\n",
       "150     564\n",
       "204     516\n",
       "36      244\n",
       "298      69\n",
       "229      54\n",
       "232      45\n",
       "198      43\n",
       "320      42\n",
       "39       33\n",
       "199      30\n",
       "215      20\n",
       "222      15\n",
       "264       8\n",
       "256       7\n",
       "Name: Info_cluster, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Info_cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "28222dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['Info_cluster'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2839e748",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df.copy()  # Make a copy of the original dataframe\n",
    "df = df.drop(columns=df.filter(regex='^Info_'))  # Drop columns starting with 'Info_'\n",
    "df['Info_cluster'] = df_temp['Info_cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "308a3e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4946 entries, 0 to 4945\n",
      "Columns: 1282 entries, Class to Info_cluster\n",
      "dtypes: float64(1280), int64(2)\n",
      "memory usage: 48.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a247ddfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9a7eca00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of outlier records: 40957\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(columns='Info_cluster')\n",
    "\n",
    "# Identify outliers using z-scores\n",
    "z_scores = (df - df.mean()) / df.std()  # Calculate z-scores for each value in the dataframe\n",
    "outliers = np.abs(z_scores) > 3  # Set threshold for outlier detection at 3 standard deviations from the mean\n",
    "n_outliers = outliers.sum().sum()  # Count total number of True values in the dataframe\n",
    "\n",
    "# Print the total number of outlier records\n",
    "print(\"Total number of outlier records:\", n_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2827f67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>feat_esm1b_0</th>\n",
       "      <th>feat_esm1b_1</th>\n",
       "      <th>feat_esm1b_2</th>\n",
       "      <th>feat_esm1b_3</th>\n",
       "      <th>feat_esm1b_4</th>\n",
       "      <th>feat_esm1b_5</th>\n",
       "      <th>feat_esm1b_6</th>\n",
       "      <th>feat_esm1b_7</th>\n",
       "      <th>feat_esm1b_8</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_esm1b_1270</th>\n",
       "      <th>feat_esm1b_1271</th>\n",
       "      <th>feat_esm1b_1272</th>\n",
       "      <th>feat_esm1b_1273</th>\n",
       "      <th>feat_esm1b_1274</th>\n",
       "      <th>feat_esm1b_1275</th>\n",
       "      <th>feat_esm1b_1276</th>\n",
       "      <th>feat_esm1b_1277</th>\n",
       "      <th>feat_esm1b_1278</th>\n",
       "      <th>feat_esm1b_1279</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4425.000000</td>\n",
       "      <td>4425.000000</td>\n",
       "      <td>4425.000000</td>\n",
       "      <td>4425.000000</td>\n",
       "      <td>4425.000000</td>\n",
       "      <td>4425.000000</td>\n",
       "      <td>4425.000000</td>\n",
       "      <td>4425.000000</td>\n",
       "      <td>4425.000000</td>\n",
       "      <td>4425.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4425.000000</td>\n",
       "      <td>4425.000000</td>\n",
       "      <td>4425.000000</td>\n",
       "      <td>4425.000000</td>\n",
       "      <td>4425.000000</td>\n",
       "      <td>4425.000000</td>\n",
       "      <td>4425.000000</td>\n",
       "      <td>4425.000000</td>\n",
       "      <td>4425.000000</td>\n",
       "      <td>4425.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.520000</td>\n",
       "      <td>0.030755</td>\n",
       "      <td>0.147561</td>\n",
       "      <td>0.133156</td>\n",
       "      <td>0.056310</td>\n",
       "      <td>-0.135560</td>\n",
       "      <td>-0.072281</td>\n",
       "      <td>-0.133773</td>\n",
       "      <td>-0.022093</td>\n",
       "      <td>-0.165872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165610</td>\n",
       "      <td>-0.068945</td>\n",
       "      <td>-0.038972</td>\n",
       "      <td>0.059846</td>\n",
       "      <td>-0.868964</td>\n",
       "      <td>-0.141099</td>\n",
       "      <td>0.039288</td>\n",
       "      <td>0.009943</td>\n",
       "      <td>0.012112</td>\n",
       "      <td>0.253001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.854263</td>\n",
       "      <td>0.174217</td>\n",
       "      <td>0.164273</td>\n",
       "      <td>0.183189</td>\n",
       "      <td>0.158925</td>\n",
       "      <td>0.171123</td>\n",
       "      <td>0.160774</td>\n",
       "      <td>0.183173</td>\n",
       "      <td>0.213266</td>\n",
       "      <td>0.194828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.197846</td>\n",
       "      <td>0.161084</td>\n",
       "      <td>0.167719</td>\n",
       "      <td>0.167216</td>\n",
       "      <td>0.460807</td>\n",
       "      <td>0.163033</td>\n",
       "      <td>0.192016</td>\n",
       "      <td>0.159694</td>\n",
       "      <td>0.203489</td>\n",
       "      <td>0.213243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.864607</td>\n",
       "      <td>-0.728582</td>\n",
       "      <td>-0.746146</td>\n",
       "      <td>-0.932043</td>\n",
       "      <td>-0.791771</td>\n",
       "      <td>-0.670408</td>\n",
       "      <td>-0.817258</td>\n",
       "      <td>-1.082430</td>\n",
       "      <td>-0.933979</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.557992</td>\n",
       "      <td>-0.744021</td>\n",
       "      <td>-0.792559</td>\n",
       "      <td>-0.810112</td>\n",
       "      <td>-1.842048</td>\n",
       "      <td>-0.720878</td>\n",
       "      <td>-0.728314</td>\n",
       "      <td>-0.713135</td>\n",
       "      <td>-1.084759</td>\n",
       "      <td>-0.984750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.072870</td>\n",
       "      <td>0.052165</td>\n",
       "      <td>0.016922</td>\n",
       "      <td>-0.034153</td>\n",
       "      <td>-0.248429</td>\n",
       "      <td>-0.175112</td>\n",
       "      <td>-0.259029</td>\n",
       "      <td>-0.165915</td>\n",
       "      <td>-0.284678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039808</td>\n",
       "      <td>-0.174682</td>\n",
       "      <td>-0.144109</td>\n",
       "      <td>-0.039304</td>\n",
       "      <td>-1.179944</td>\n",
       "      <td>-0.249053</td>\n",
       "      <td>-0.091472</td>\n",
       "      <td>-0.075154</td>\n",
       "      <td>-0.115939</td>\n",
       "      <td>0.153016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.041457</td>\n",
       "      <td>0.153511</td>\n",
       "      <td>0.129611</td>\n",
       "      <td>0.061203</td>\n",
       "      <td>-0.138085</td>\n",
       "      <td>-0.075022</td>\n",
       "      <td>-0.135976</td>\n",
       "      <td>-0.023361</td>\n",
       "      <td>-0.172447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146975</td>\n",
       "      <td>-0.065006</td>\n",
       "      <td>-0.034378</td>\n",
       "      <td>0.066762</td>\n",
       "      <td>-0.937241</td>\n",
       "      <td>-0.153513</td>\n",
       "      <td>0.033876</td>\n",
       "      <td>0.022752</td>\n",
       "      <td>0.032889</td>\n",
       "      <td>0.272629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.150047</td>\n",
       "      <td>0.247211</td>\n",
       "      <td>0.246416</td>\n",
       "      <td>0.154601</td>\n",
       "      <td>-0.022724</td>\n",
       "      <td>0.031777</td>\n",
       "      <td>-0.014520</td>\n",
       "      <td>0.127583</td>\n",
       "      <td>-0.049705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261899</td>\n",
       "      <td>0.032938</td>\n",
       "      <td>0.074039</td>\n",
       "      <td>0.165388</td>\n",
       "      <td>-0.652044</td>\n",
       "      <td>-0.049282</td>\n",
       "      <td>0.164783</td>\n",
       "      <td>0.110488</td>\n",
       "      <td>0.154810</td>\n",
       "      <td>0.387973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.729142</td>\n",
       "      <td>1.169529</td>\n",
       "      <td>0.897457</td>\n",
       "      <td>0.947781</td>\n",
       "      <td>0.583465</td>\n",
       "      <td>0.699755</td>\n",
       "      <td>0.527441</td>\n",
       "      <td>0.803797</td>\n",
       "      <td>0.689671</td>\n",
       "      <td>...</td>\n",
       "      <td>1.554905</td>\n",
       "      <td>0.636953</td>\n",
       "      <td>0.585061</td>\n",
       "      <td>0.854849</td>\n",
       "      <td>1.567513</td>\n",
       "      <td>0.783904</td>\n",
       "      <td>0.743291</td>\n",
       "      <td>0.550096</td>\n",
       "      <td>0.640430</td>\n",
       "      <td>0.955284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 1281 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Class  feat_esm1b_0  feat_esm1b_1  feat_esm1b_2  feat_esm1b_3  \\\n",
       "count  4425.000000   4425.000000   4425.000000   4425.000000   4425.000000   \n",
       "mean     -0.520000      0.030755      0.147561      0.133156      0.056310   \n",
       "std       0.854263      0.174217      0.164273      0.183189      0.158925   \n",
       "min      -1.000000     -0.864607     -0.728582     -0.746146     -0.932043   \n",
       "25%      -1.000000     -0.072870      0.052165      0.016922     -0.034153   \n",
       "50%      -1.000000      0.041457      0.153511      0.129611      0.061203   \n",
       "75%      -1.000000      0.150047      0.247211      0.246416      0.154601   \n",
       "max       1.000000      0.729142      1.169529      0.897457      0.947781   \n",
       "\n",
       "       feat_esm1b_4  feat_esm1b_5  feat_esm1b_6  feat_esm1b_7  feat_esm1b_8  \\\n",
       "count   4425.000000   4425.000000   4425.000000   4425.000000   4425.000000   \n",
       "mean      -0.135560     -0.072281     -0.133773     -0.022093     -0.165872   \n",
       "std        0.171123      0.160774      0.183173      0.213266      0.194828   \n",
       "min       -0.791771     -0.670408     -0.817258     -1.082430     -0.933979   \n",
       "25%       -0.248429     -0.175112     -0.259029     -0.165915     -0.284678   \n",
       "50%       -0.138085     -0.075022     -0.135976     -0.023361     -0.172447   \n",
       "75%       -0.022724      0.031777     -0.014520      0.127583     -0.049705   \n",
       "max        0.583465      0.699755      0.527441      0.803797      0.689671   \n",
       "\n",
       "       ...  feat_esm1b_1270  feat_esm1b_1271  feat_esm1b_1272  \\\n",
       "count  ...      4425.000000      4425.000000      4425.000000   \n",
       "mean   ...         0.165610        -0.068945        -0.038972   \n",
       "std    ...         0.197846         0.161084         0.167719   \n",
       "min    ...        -0.557992        -0.744021        -0.792559   \n",
       "25%    ...         0.039808        -0.174682        -0.144109   \n",
       "50%    ...         0.146975        -0.065006        -0.034378   \n",
       "75%    ...         0.261899         0.032938         0.074039   \n",
       "max    ...         1.554905         0.636953         0.585061   \n",
       "\n",
       "       feat_esm1b_1273  feat_esm1b_1274  feat_esm1b_1275  feat_esm1b_1276  \\\n",
       "count      4425.000000      4425.000000      4425.000000      4425.000000   \n",
       "mean          0.059846        -0.868964        -0.141099         0.039288   \n",
       "std           0.167216         0.460807         0.163033         0.192016   \n",
       "min          -0.810112        -1.842048        -0.720878        -0.728314   \n",
       "25%          -0.039304        -1.179944        -0.249053        -0.091472   \n",
       "50%           0.066762        -0.937241        -0.153513         0.033876   \n",
       "75%           0.165388        -0.652044        -0.049282         0.164783   \n",
       "max           0.854849         1.567513         0.783904         0.743291   \n",
       "\n",
       "       feat_esm1b_1277  feat_esm1b_1278  feat_esm1b_1279  \n",
       "count      4425.000000      4425.000000      4425.000000  \n",
       "mean          0.009943         0.012112         0.253001  \n",
       "std           0.159694         0.203489         0.213243  \n",
       "min          -0.713135        -1.084759        -0.984750  \n",
       "25%          -0.075154        -0.115939         0.153016  \n",
       "50%           0.022752         0.032889         0.272629  \n",
       "75%           0.110488         0.154810         0.387973  \n",
       "max           0.550096         0.640430         0.955284  \n",
       "\n",
       "[8 rows x 1281 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c5cbaf25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    3363\n",
       " 1    1062\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1aaba78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "242dd434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate z-scores for each value in the dataframe\n",
    "z_scores = (clean_df - clean_df.mean()) / clean_df.std()\n",
    "\n",
    "# Set threshold for outlier detection at 3 standard deviations from the mean\n",
    "threshold = 3\n",
    "\n",
    "# Find the indices of all data points with z-scores above the threshold\n",
    "outlier_indices = np.where(np.abs(z_scores) > threshold)\n",
    "\n",
    "# Remove the rows with outlier indices\n",
    "clean_df = clean_df[(z_scores <= threshold).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "659f94cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2448, 1281)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a542b4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['Info_cluster'] = df_temp['Info_cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6c915710",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create a dataframe of features by selecting all columns except for 'Class'\n",
    "features = clean_df.iloc[:, clean_df.columns != 'Class']\n",
    "\n",
    "# Create a series of the target variable ('Class')\n",
    "target = clean_df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "84ebd95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "99b69173",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['Class'] = clean_df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5199d25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    1407\n",
       " 1     551\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1166ae69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from boruta import BorutaPy\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ced26620",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_clean = X_train.drop(['Class', 'Info_cluster'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "03e6a537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_esm1b_0</th>\n",
       "      <th>feat_esm1b_1</th>\n",
       "      <th>feat_esm1b_2</th>\n",
       "      <th>feat_esm1b_3</th>\n",
       "      <th>feat_esm1b_4</th>\n",
       "      <th>feat_esm1b_5</th>\n",
       "      <th>feat_esm1b_6</th>\n",
       "      <th>feat_esm1b_7</th>\n",
       "      <th>feat_esm1b_8</th>\n",
       "      <th>feat_esm1b_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_esm1b_1270</th>\n",
       "      <th>feat_esm1b_1271</th>\n",
       "      <th>feat_esm1b_1272</th>\n",
       "      <th>feat_esm1b_1273</th>\n",
       "      <th>feat_esm1b_1274</th>\n",
       "      <th>feat_esm1b_1275</th>\n",
       "      <th>feat_esm1b_1276</th>\n",
       "      <th>feat_esm1b_1277</th>\n",
       "      <th>feat_esm1b_1278</th>\n",
       "      <th>feat_esm1b_1279</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3975</th>\n",
       "      <td>0.050211</td>\n",
       "      <td>0.097243</td>\n",
       "      <td>0.079619</td>\n",
       "      <td>0.014110</td>\n",
       "      <td>0.038612</td>\n",
       "      <td>0.335759</td>\n",
       "      <td>-0.091919</td>\n",
       "      <td>-0.084824</td>\n",
       "      <td>-0.137887</td>\n",
       "      <td>0.068239</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053649</td>\n",
       "      <td>-0.105805</td>\n",
       "      <td>-0.249456</td>\n",
       "      <td>0.224054</td>\n",
       "      <td>-0.627018</td>\n",
       "      <td>-0.044531</td>\n",
       "      <td>0.211824</td>\n",
       "      <td>-0.199749</td>\n",
       "      <td>-0.039331</td>\n",
       "      <td>0.124213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>-0.089267</td>\n",
       "      <td>0.032304</td>\n",
       "      <td>0.142255</td>\n",
       "      <td>-0.047216</td>\n",
       "      <td>-0.437265</td>\n",
       "      <td>-0.078436</td>\n",
       "      <td>-0.196060</td>\n",
       "      <td>-0.014184</td>\n",
       "      <td>-0.395557</td>\n",
       "      <td>-0.091702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147397</td>\n",
       "      <td>-0.209335</td>\n",
       "      <td>0.015844</td>\n",
       "      <td>0.101275</td>\n",
       "      <td>-1.485813</td>\n",
       "      <td>-0.272853</td>\n",
       "      <td>0.107751</td>\n",
       "      <td>0.067596</td>\n",
       "      <td>0.017883</td>\n",
       "      <td>0.224278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0.120327</td>\n",
       "      <td>0.155274</td>\n",
       "      <td>0.296128</td>\n",
       "      <td>-0.141289</td>\n",
       "      <td>-0.299129</td>\n",
       "      <td>0.019361</td>\n",
       "      <td>-0.116259</td>\n",
       "      <td>-0.009074</td>\n",
       "      <td>-0.132490</td>\n",
       "      <td>0.194819</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137570</td>\n",
       "      <td>-0.079843</td>\n",
       "      <td>-0.037795</td>\n",
       "      <td>0.300911</td>\n",
       "      <td>-1.639716</td>\n",
       "      <td>-0.199560</td>\n",
       "      <td>0.032484</td>\n",
       "      <td>0.185506</td>\n",
       "      <td>0.064363</td>\n",
       "      <td>0.296593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599</th>\n",
       "      <td>-0.100797</td>\n",
       "      <td>0.129846</td>\n",
       "      <td>0.444591</td>\n",
       "      <td>0.049932</td>\n",
       "      <td>-0.206813</td>\n",
       "      <td>0.117044</td>\n",
       "      <td>-0.109908</td>\n",
       "      <td>-0.279209</td>\n",
       "      <td>-0.314691</td>\n",
       "      <td>-0.049033</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179443</td>\n",
       "      <td>-0.432061</td>\n",
       "      <td>0.011489</td>\n",
       "      <td>-0.119693</td>\n",
       "      <td>-1.208877</td>\n",
       "      <td>-0.414384</td>\n",
       "      <td>-0.010910</td>\n",
       "      <td>0.186598</td>\n",
       "      <td>0.174763</td>\n",
       "      <td>0.375242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4305</th>\n",
       "      <td>0.086014</td>\n",
       "      <td>0.149840</td>\n",
       "      <td>-0.100943</td>\n",
       "      <td>0.110624</td>\n",
       "      <td>-0.246441</td>\n",
       "      <td>-0.116427</td>\n",
       "      <td>-0.026956</td>\n",
       "      <td>-0.271807</td>\n",
       "      <td>-0.225726</td>\n",
       "      <td>-0.055780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198482</td>\n",
       "      <td>-0.120731</td>\n",
       "      <td>-0.014633</td>\n",
       "      <td>0.239760</td>\n",
       "      <td>-1.021704</td>\n",
       "      <td>-0.096593</td>\n",
       "      <td>-0.183278</td>\n",
       "      <td>-0.001779</td>\n",
       "      <td>0.096297</td>\n",
       "      <td>0.196827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1280 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feat_esm1b_0  feat_esm1b_1  feat_esm1b_2  feat_esm1b_3  feat_esm1b_4  \\\n",
       "3975      0.050211      0.097243      0.079619      0.014110      0.038612   \n",
       "173      -0.089267      0.032304      0.142255     -0.047216     -0.437265   \n",
       "399       0.120327      0.155274      0.296128     -0.141289     -0.299129   \n",
       "3599     -0.100797      0.129846      0.444591      0.049932     -0.206813   \n",
       "4305      0.086014      0.149840     -0.100943      0.110624     -0.246441   \n",
       "\n",
       "      feat_esm1b_5  feat_esm1b_6  feat_esm1b_7  feat_esm1b_8  feat_esm1b_9  \\\n",
       "3975      0.335759     -0.091919     -0.084824     -0.137887      0.068239   \n",
       "173      -0.078436     -0.196060     -0.014184     -0.395557     -0.091702   \n",
       "399       0.019361     -0.116259     -0.009074     -0.132490      0.194819   \n",
       "3599      0.117044     -0.109908     -0.279209     -0.314691     -0.049033   \n",
       "4305     -0.116427     -0.026956     -0.271807     -0.225726     -0.055780   \n",
       "\n",
       "      ...  feat_esm1b_1270  feat_esm1b_1271  feat_esm1b_1272  feat_esm1b_1273  \\\n",
       "3975  ...        -0.053649        -0.105805        -0.249456         0.224054   \n",
       "173   ...         0.147397        -0.209335         0.015844         0.101275   \n",
       "399   ...         0.137570        -0.079843        -0.037795         0.300911   \n",
       "3599  ...         0.179443        -0.432061         0.011489        -0.119693   \n",
       "4305  ...         0.198482        -0.120731        -0.014633         0.239760   \n",
       "\n",
       "      feat_esm1b_1274  feat_esm1b_1275  feat_esm1b_1276  feat_esm1b_1277  \\\n",
       "3975        -0.627018        -0.044531         0.211824        -0.199749   \n",
       "173         -1.485813        -0.272853         0.107751         0.067596   \n",
       "399         -1.639716        -0.199560         0.032484         0.185506   \n",
       "3599        -1.208877        -0.414384        -0.010910         0.186598   \n",
       "4305        -1.021704        -0.096593        -0.183278        -0.001779   \n",
       "\n",
       "      feat_esm1b_1278  feat_esm1b_1279  \n",
       "3975        -0.039331         0.124213  \n",
       "173          0.017883         0.224278  \n",
       "399          0.064363         0.296593  \n",
       "3599         0.174763         0.375242  \n",
       "4305         0.096297         0.196827  \n",
       "\n",
       "[5 rows x 1280 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "39559a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1958, 1280), (1958,))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_clean.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "790d4141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t1 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t1280\n",
      "Rejected: \t0\n",
      "Iteration: \t2 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t1280\n",
      "Rejected: \t0\n",
      "Iteration: \t3 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t1280\n",
      "Rejected: \t0\n",
      "Iteration: \t4 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t1280\n",
      "Rejected: \t0\n",
      "Iteration: \t5 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t1280\n",
      "Rejected: \t0\n",
      "Iteration: \t6 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t1280\n",
      "Rejected: \t0\n",
      "Iteration: \t7 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t1280\n",
      "Rejected: \t0\n",
      "Iteration: \t8 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t1280\n",
      "Rejected: \t0\n",
      "Iteration: \t9 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t1280\n",
      "Rejected: \t0\n",
      "Iteration: \t10 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t1280\n",
      "Rejected: \t0\n",
      "Iteration: \t11 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t1280\n",
      "Rejected: \t0\n",
      "Iteration: \t12 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t1280\n",
      "Rejected: \t0\n",
      "Iteration: \t13 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t1280\n",
      "Rejected: \t0\n",
      "Iteration: \t14 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t1280\n",
      "Rejected: \t0\n",
      "Iteration: \t15 / 100\n",
      "Confirmed: \t209\n",
      "Tentative: \t519\n",
      "Rejected: \t552\n",
      "Iteration: \t16 / 100\n",
      "Confirmed: \t209\n",
      "Tentative: \t519\n",
      "Rejected: \t552\n",
      "Iteration: \t17 / 100\n",
      "Confirmed: \t209\n",
      "Tentative: \t519\n",
      "Rejected: \t552\n",
      "Iteration: \t18 / 100\n",
      "Confirmed: \t209\n",
      "Tentative: \t519\n",
      "Rejected: \t552\n",
      "Iteration: \t19 / 100\n",
      "Confirmed: \t233\n",
      "Tentative: \t410\n",
      "Rejected: \t637\n",
      "Iteration: \t20 / 100\n",
      "Confirmed: \t233\n",
      "Tentative: \t410\n",
      "Rejected: \t637\n",
      "Iteration: \t21 / 100\n",
      "Confirmed: \t233\n",
      "Tentative: \t410\n",
      "Rejected: \t637\n",
      "Iteration: \t22 / 100\n",
      "Confirmed: \t233\n",
      "Tentative: \t410\n",
      "Rejected: \t637\n",
      "Iteration: \t23 / 100\n",
      "Confirmed: \t235\n",
      "Tentative: \t364\n",
      "Rejected: \t681\n",
      "Iteration: \t24 / 100\n",
      "Confirmed: \t235\n",
      "Tentative: \t364\n",
      "Rejected: \t681\n",
      "Iteration: \t25 / 100\n",
      "Confirmed: \t235\n",
      "Tentative: \t364\n",
      "Rejected: \t681\n",
      "Iteration: \t26 / 100\n",
      "Confirmed: \t235\n",
      "Tentative: \t364\n",
      "Rejected: \t681\n",
      "Iteration: \t27 / 100\n",
      "Confirmed: \t238\n",
      "Tentative: \t331\n",
      "Rejected: \t711\n",
      "Iteration: \t28 / 100\n",
      "Confirmed: \t238\n",
      "Tentative: \t331\n",
      "Rejected: \t711\n",
      "Iteration: \t29 / 100\n",
      "Confirmed: \t238\n",
      "Tentative: \t331\n",
      "Rejected: \t711\n",
      "Iteration: \t30 / 100\n",
      "Confirmed: \t253\n",
      "Tentative: \t300\n",
      "Rejected: \t727\n",
      "Iteration: \t31 / 100\n",
      "Confirmed: \t253\n",
      "Tentative: \t300\n",
      "Rejected: \t727\n",
      "Iteration: \t32 / 100\n",
      "Confirmed: \t253\n",
      "Tentative: \t300\n",
      "Rejected: \t727\n",
      "Iteration: \t33 / 100\n",
      "Confirmed: \t260\n",
      "Tentative: \t289\n",
      "Rejected: \t731\n",
      "Iteration: \t34 / 100\n",
      "Confirmed: \t260\n",
      "Tentative: \t289\n",
      "Rejected: \t731\n",
      "Iteration: \t35 / 100\n",
      "Confirmed: \t260\n",
      "Tentative: \t289\n",
      "Rejected: \t731\n",
      "Iteration: \t36 / 100\n",
      "Confirmed: \t265\n",
      "Tentative: \t275\n",
      "Rejected: \t740\n",
      "Iteration: \t37 / 100\n",
      "Confirmed: \t265\n",
      "Tentative: \t275\n",
      "Rejected: \t740\n",
      "Iteration: \t38 / 100\n",
      "Confirmed: \t265\n",
      "Tentative: \t275\n",
      "Rejected: \t740\n",
      "Iteration: \t39 / 100\n",
      "Confirmed: \t271\n",
      "Tentative: \t262\n",
      "Rejected: \t747\n",
      "Iteration: \t40 / 100\n",
      "Confirmed: \t271\n",
      "Tentative: \t262\n",
      "Rejected: \t747\n",
      "Iteration: \t41 / 100\n",
      "Confirmed: \t271\n",
      "Tentative: \t262\n",
      "Rejected: \t747\n",
      "Iteration: \t42 / 100\n",
      "Confirmed: \t274\n",
      "Tentative: \t251\n",
      "Rejected: \t755\n",
      "Iteration: \t43 / 100\n",
      "Confirmed: \t274\n",
      "Tentative: \t251\n",
      "Rejected: \t755\n",
      "Iteration: \t44 / 100\n",
      "Confirmed: \t274\n",
      "Tentative: \t251\n",
      "Rejected: \t755\n",
      "Iteration: \t45 / 100\n",
      "Confirmed: \t276\n",
      "Tentative: \t243\n",
      "Rejected: \t761\n",
      "Iteration: \t46 / 100\n",
      "Confirmed: \t276\n",
      "Tentative: \t243\n",
      "Rejected: \t761\n",
      "Iteration: \t47 / 100\n",
      "Confirmed: \t276\n",
      "Tentative: \t243\n",
      "Rejected: \t761\n",
      "Iteration: \t48 / 100\n",
      "Confirmed: \t279\n",
      "Tentative: \t237\n",
      "Rejected: \t764\n",
      "Iteration: \t49 / 100\n",
      "Confirmed: \t279\n",
      "Tentative: \t237\n",
      "Rejected: \t764\n",
      "Iteration: \t50 / 100\n",
      "Confirmed: \t279\n",
      "Tentative: \t237\n",
      "Rejected: \t764\n",
      "Iteration: \t51 / 100\n",
      "Confirmed: \t280\n",
      "Tentative: \t229\n",
      "Rejected: \t771\n",
      "Iteration: \t52 / 100\n",
      "Confirmed: \t280\n",
      "Tentative: \t229\n",
      "Rejected: \t771\n",
      "Iteration: \t53 / 100\n",
      "Confirmed: \t280\n",
      "Tentative: \t229\n",
      "Rejected: \t771\n",
      "Iteration: \t54 / 100\n",
      "Confirmed: \t284\n",
      "Tentative: \t225\n",
      "Rejected: \t771\n",
      "Iteration: \t55 / 100\n",
      "Confirmed: \t284\n",
      "Tentative: \t225\n",
      "Rejected: \t771\n",
      "Iteration: \t56 / 100\n",
      "Confirmed: \t286\n",
      "Tentative: \t220\n",
      "Rejected: \t774\n",
      "Iteration: \t57 / 100\n",
      "Confirmed: \t286\n",
      "Tentative: \t220\n",
      "Rejected: \t774\n",
      "Iteration: \t58 / 100\n",
      "Confirmed: \t286\n",
      "Tentative: \t220\n",
      "Rejected: \t774\n",
      "Iteration: \t59 / 100\n",
      "Confirmed: \t289\n",
      "Tentative: \t216\n",
      "Rejected: \t775\n",
      "Iteration: \t60 / 100\n",
      "Confirmed: \t289\n",
      "Tentative: \t216\n",
      "Rejected: \t775\n",
      "Iteration: \t61 / 100\n",
      "Confirmed: \t289\n",
      "Tentative: \t216\n",
      "Rejected: \t775\n",
      "Iteration: \t62 / 100\n",
      "Confirmed: \t290\n",
      "Tentative: \t213\n",
      "Rejected: \t777\n",
      "Iteration: \t63 / 100\n",
      "Confirmed: \t290\n",
      "Tentative: \t213\n",
      "Rejected: \t777\n",
      "Iteration: \t64 / 100\n",
      "Confirmed: \t293\n",
      "Tentative: \t208\n",
      "Rejected: \t779\n",
      "Iteration: \t65 / 100\n",
      "Confirmed: \t293\n",
      "Tentative: \t208\n",
      "Rejected: \t779\n",
      "Iteration: \t66 / 100\n",
      "Confirmed: \t293\n",
      "Tentative: \t208\n",
      "Rejected: \t779\n",
      "Iteration: \t67 / 100\n",
      "Confirmed: \t293\n",
      "Tentative: \t206\n",
      "Rejected: \t781\n",
      "Iteration: \t68 / 100\n",
      "Confirmed: \t293\n",
      "Tentative: \t206\n",
      "Rejected: \t781\n",
      "Iteration: \t69 / 100\n",
      "Confirmed: \t293\n",
      "Tentative: \t206\n",
      "Rejected: \t781\n",
      "Iteration: \t70 / 100\n",
      "Confirmed: \t295\n",
      "Tentative: \t204\n",
      "Rejected: \t781\n",
      "Iteration: \t71 / 100\n",
      "Confirmed: \t295\n",
      "Tentative: \t204\n",
      "Rejected: \t781\n",
      "Iteration: \t72 / 100\n",
      "Confirmed: \t295\n",
      "Tentative: \t204\n",
      "Rejected: \t781\n",
      "Iteration: \t73 / 100\n",
      "Confirmed: \t295\n",
      "Tentative: \t204\n",
      "Rejected: \t781\n",
      "Iteration: \t74 / 100\n",
      "Confirmed: \t295\n",
      "Tentative: \t204\n",
      "Rejected: \t781\n",
      "Iteration: \t75 / 100\n",
      "Confirmed: \t295\n",
      "Tentative: \t200\n",
      "Rejected: \t785\n",
      "Iteration: \t76 / 100\n",
      "Confirmed: \t295\n",
      "Tentative: \t200\n",
      "Rejected: \t785\n",
      "Iteration: \t77 / 100\n",
      "Confirmed: \t295\n",
      "Tentative: \t200\n",
      "Rejected: \t785\n",
      "Iteration: \t78 / 100\n",
      "Confirmed: \t296\n",
      "Tentative: \t198\n",
      "Rejected: \t786\n",
      "Iteration: \t79 / 100\n",
      "Confirmed: \t296\n",
      "Tentative: \t198\n",
      "Rejected: \t786\n",
      "Iteration: \t80 / 100\n",
      "Confirmed: \t298\n",
      "Tentative: \t196\n",
      "Rejected: \t786\n",
      "Iteration: \t81 / 100\n",
      "Confirmed: \t298\n",
      "Tentative: \t196\n",
      "Rejected: \t786\n",
      "Iteration: \t82 / 100\n",
      "Confirmed: \t298\n",
      "Tentative: \t196\n",
      "Rejected: \t786\n",
      "Iteration: \t83 / 100\n",
      "Confirmed: \t300\n",
      "Tentative: \t192\n",
      "Rejected: \t788\n",
      "Iteration: \t84 / 100\n",
      "Confirmed: \t300\n",
      "Tentative: \t192\n",
      "Rejected: \t788\n",
      "Iteration: \t85 / 100\n",
      "Confirmed: \t302\n",
      "Tentative: \t188\n",
      "Rejected: \t790\n",
      "Iteration: \t86 / 100\n",
      "Confirmed: \t302\n",
      "Tentative: \t188\n",
      "Rejected: \t790\n",
      "Iteration: \t87 / 100\n",
      "Confirmed: \t302\n",
      "Tentative: \t188\n",
      "Rejected: \t790\n",
      "Iteration: \t88 / 100\n",
      "Confirmed: \t305\n",
      "Tentative: \t183\n",
      "Rejected: \t792\n",
      "Iteration: \t89 / 100\n",
      "Confirmed: \t305\n",
      "Tentative: \t183\n",
      "Rejected: \t792\n",
      "Iteration: \t90 / 100\n",
      "Confirmed: \t306\n",
      "Tentative: \t178\n",
      "Rejected: \t796\n",
      "Iteration: \t91 / 100\n",
      "Confirmed: \t306\n",
      "Tentative: \t178\n",
      "Rejected: \t796\n",
      "Iteration: \t92 / 100\n",
      "Confirmed: \t306\n",
      "Tentative: \t178\n",
      "Rejected: \t796\n",
      "Iteration: \t93 / 100\n",
      "Confirmed: \t309\n",
      "Tentative: \t173\n",
      "Rejected: \t798\n",
      "Iteration: \t94 / 100\n",
      "Confirmed: \t309\n",
      "Tentative: \t173\n",
      "Rejected: \t798\n",
      "Iteration: \t95 / 100\n",
      "Confirmed: \t309\n",
      "Tentative: \t172\n",
      "Rejected: \t799\n",
      "Iteration: \t96 / 100\n",
      "Confirmed: \t309\n",
      "Tentative: \t172\n",
      "Rejected: \t799\n",
      "Iteration: \t97 / 100\n",
      "Confirmed: \t309\n",
      "Tentative: \t172\n",
      "Rejected: \t799\n",
      "Iteration: \t98 / 100\n",
      "Confirmed: \t310\n",
      "Tentative: \t169\n",
      "Rejected: \t801\n",
      "Iteration: \t99 / 100\n",
      "Confirmed: \t310\n",
      "Tentative: \t169\n",
      "Rejected: \t801\n",
      "\n",
      "\n",
      "BorutaPy finished running.\n",
      "\n",
      "Iteration: \t100 / 100\n",
      "Confirmed: \t310\n",
      "Tentative: \t83\n",
      "Rejected: \t801\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BorutaPy(estimator=RandomForestClassifier(class_weight='balanced', max_depth=5,\n",
       "                                          n_estimators=619, n_jobs=-1,\n",
       "                                          random_state=RandomState(MT19937) at 0x26E0C8F7540),\n",
       "         n_estimators='auto',\n",
       "         random_state=RandomState(MT19937) at 0x26E0C8F7540, two_step=False,\n",
       "         verbose=3)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random forest classifier\n",
    "rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5)\n",
    "\n",
    "# Create a Boruta feature selector instance\n",
    "boruta_selector = BorutaPy(rf, n_estimators='auto', verbose=3, random_state=1, two_step=False)\n",
    "\n",
    "# Fit the Boruta selector to the training data\n",
    "boruta_selector.fit(X_train_clean.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bbc69616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of relevant features: 310\n"
     ]
    }
   ],
   "source": [
    "n_relevant_features = boruta_selector.n_features_\n",
    "print(\"Number of relevant features:\", n_relevant_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1d66cf6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['feat_esm1b_1', 'feat_esm1b_2', 'feat_esm1b_3', 'feat_esm1b_6', 'feat_esm1b_11', 'feat_esm1b_15', 'feat_esm1b_16', 'feat_esm1b_18', 'feat_esm1b_19', 'feat_esm1b_22', 'feat_esm1b_27', 'feat_esm1b_39', 'feat_esm1b_46', 'feat_esm1b_51', 'feat_esm1b_52', 'feat_esm1b_53', 'feat_esm1b_57', 'feat_esm1b_69', 'feat_esm1b_70', 'feat_esm1b_76', 'feat_esm1b_80', 'feat_esm1b_83', 'feat_esm1b_86', 'feat_esm1b_87', 'feat_esm1b_90', 'feat_esm1b_91', 'feat_esm1b_93', 'feat_esm1b_94', 'feat_esm1b_101', 'feat_esm1b_105', 'feat_esm1b_112', 'feat_esm1b_120', 'feat_esm1b_134', 'feat_esm1b_140', 'feat_esm1b_148', 'feat_esm1b_149', 'feat_esm1b_151', 'feat_esm1b_154', 'feat_esm1b_159', 'feat_esm1b_162', 'feat_esm1b_167', 'feat_esm1b_175', 'feat_esm1b_176', 'feat_esm1b_178', 'feat_esm1b_179', 'feat_esm1b_180', 'feat_esm1b_181', 'feat_esm1b_188', 'feat_esm1b_200', 'feat_esm1b_203', 'feat_esm1b_210', 'feat_esm1b_217', 'feat_esm1b_228', 'feat_esm1b_229', 'feat_esm1b_236', 'feat_esm1b_245', 'feat_esm1b_246', 'feat_esm1b_247', 'feat_esm1b_253', 'feat_esm1b_257', 'feat_esm1b_266', 'feat_esm1b_267', 'feat_esm1b_277', 'feat_esm1b_278', 'feat_esm1b_279', 'feat_esm1b_280', 'feat_esm1b_282', 'feat_esm1b_284', 'feat_esm1b_301', 'feat_esm1b_304', 'feat_esm1b_307', 'feat_esm1b_313', 'feat_esm1b_315', 'feat_esm1b_321', 'feat_esm1b_323', 'feat_esm1b_329', 'feat_esm1b_349', 'feat_esm1b_351', 'feat_esm1b_355', 'feat_esm1b_361', 'feat_esm1b_362', 'feat_esm1b_365', 'feat_esm1b_368', 'feat_esm1b_376', 'feat_esm1b_382', 'feat_esm1b_383', 'feat_esm1b_384', 'feat_esm1b_385', 'feat_esm1b_388', 'feat_esm1b_391', 'feat_esm1b_396', 'feat_esm1b_397', 'feat_esm1b_400', 'feat_esm1b_404', 'feat_esm1b_407', 'feat_esm1b_410', 'feat_esm1b_411', 'feat_esm1b_415', 'feat_esm1b_417', 'feat_esm1b_418', 'feat_esm1b_421', 'feat_esm1b_424', 'feat_esm1b_430', 'feat_esm1b_433', 'feat_esm1b_437', 'feat_esm1b_438', 'feat_esm1b_442', 'feat_esm1b_451', 'feat_esm1b_454', 'feat_esm1b_458', 'feat_esm1b_460', 'feat_esm1b_461', 'feat_esm1b_468', 'feat_esm1b_469', 'feat_esm1b_473', 'feat_esm1b_474', 'feat_esm1b_476', 'feat_esm1b_478', 'feat_esm1b_479', 'feat_esm1b_480', 'feat_esm1b_481', 'feat_esm1b_493', 'feat_esm1b_494', 'feat_esm1b_500', 'feat_esm1b_501', 'feat_esm1b_502', 'feat_esm1b_509', 'feat_esm1b_512', 'feat_esm1b_514', 'feat_esm1b_519', 'feat_esm1b_521', 'feat_esm1b_526', 'feat_esm1b_529', 'feat_esm1b_533', 'feat_esm1b_536', 'feat_esm1b_537', 'feat_esm1b_545', 'feat_esm1b_549', 'feat_esm1b_550', 'feat_esm1b_551', 'feat_esm1b_555', 'feat_esm1b_567', 'feat_esm1b_568', 'feat_esm1b_576', 'feat_esm1b_577', 'feat_esm1b_580', 'feat_esm1b_586', 'feat_esm1b_593', 'feat_esm1b_594', 'feat_esm1b_615', 'feat_esm1b_616', 'feat_esm1b_621', 'feat_esm1b_624', 'feat_esm1b_640', 'feat_esm1b_642', 'feat_esm1b_646', 'feat_esm1b_647', 'feat_esm1b_654', 'feat_esm1b_658', 'feat_esm1b_660', 'feat_esm1b_662', 'feat_esm1b_665', 'feat_esm1b_669', 'feat_esm1b_670', 'feat_esm1b_671', 'feat_esm1b_675', 'feat_esm1b_677', 'feat_esm1b_682', 'feat_esm1b_685', 'feat_esm1b_686', 'feat_esm1b_688', 'feat_esm1b_692', 'feat_esm1b_701', 'feat_esm1b_715', 'feat_esm1b_716', 'feat_esm1b_718', 'feat_esm1b_723', 'feat_esm1b_728', 'feat_esm1b_730', 'feat_esm1b_731', 'feat_esm1b_733', 'feat_esm1b_739', 'feat_esm1b_742', 'feat_esm1b_743', 'feat_esm1b_751', 'feat_esm1b_756', 'feat_esm1b_766', 'feat_esm1b_770', 'feat_esm1b_776', 'feat_esm1b_777', 'feat_esm1b_783', 'feat_esm1b_789', 'feat_esm1b_791', 'feat_esm1b_795', 'feat_esm1b_802', 'feat_esm1b_810', 'feat_esm1b_819', 'feat_esm1b_835', 'feat_esm1b_842', 'feat_esm1b_843', 'feat_esm1b_845', 'feat_esm1b_847', 'feat_esm1b_848', 'feat_esm1b_859', 'feat_esm1b_877', 'feat_esm1b_878', 'feat_esm1b_882', 'feat_esm1b_883', 'feat_esm1b_888', 'feat_esm1b_892', 'feat_esm1b_895', 'feat_esm1b_902', 'feat_esm1b_908', 'feat_esm1b_916', 'feat_esm1b_917', 'feat_esm1b_923', 'feat_esm1b_925', 'feat_esm1b_933', 'feat_esm1b_935', 'feat_esm1b_947', 'feat_esm1b_957', 'feat_esm1b_962', 'feat_esm1b_977', 'feat_esm1b_980', 'feat_esm1b_981', 'feat_esm1b_982', 'feat_esm1b_984', 'feat_esm1b_985', 'feat_esm1b_988', 'feat_esm1b_990', 'feat_esm1b_992', 'feat_esm1b_995', 'feat_esm1b_996', 'feat_esm1b_1001', 'feat_esm1b_1003', 'feat_esm1b_1006', 'feat_esm1b_1007', 'feat_esm1b_1010', 'feat_esm1b_1019', 'feat_esm1b_1021', 'feat_esm1b_1025', 'feat_esm1b_1026', 'feat_esm1b_1027', 'feat_esm1b_1030', 'feat_esm1b_1036', 'feat_esm1b_1038', 'feat_esm1b_1040', 'feat_esm1b_1048', 'feat_esm1b_1052', 'feat_esm1b_1055', 'feat_esm1b_1057', 'feat_esm1b_1067', 'feat_esm1b_1072', 'feat_esm1b_1078', 'feat_esm1b_1080', 'feat_esm1b_1083', 'feat_esm1b_1086', 'feat_esm1b_1089', 'feat_esm1b_1090', 'feat_esm1b_1094', 'feat_esm1b_1097', 'feat_esm1b_1098', 'feat_esm1b_1101', 'feat_esm1b_1108', 'feat_esm1b_1116', 'feat_esm1b_1127', 'feat_esm1b_1133', 'feat_esm1b_1134', 'feat_esm1b_1135', 'feat_esm1b_1138', 'feat_esm1b_1139', 'feat_esm1b_1140', 'feat_esm1b_1156', 'feat_esm1b_1158', 'feat_esm1b_1163', 'feat_esm1b_1166', 'feat_esm1b_1168', 'feat_esm1b_1169', 'feat_esm1b_1171', 'feat_esm1b_1179', 'feat_esm1b_1184', 'feat_esm1b_1185', 'feat_esm1b_1188', 'feat_esm1b_1189', 'feat_esm1b_1197', 'feat_esm1b_1202', 'feat_esm1b_1207', 'feat_esm1b_1208', 'feat_esm1b_1209', 'feat_esm1b_1210', 'feat_esm1b_1211', 'feat_esm1b_1213', 'feat_esm1b_1222', 'feat_esm1b_1224', 'feat_esm1b_1234', 'feat_esm1b_1238', 'feat_esm1b_1239', 'feat_esm1b_1247', 'feat_esm1b_1249', 'feat_esm1b_1252', 'feat_esm1b_1255', 'feat_esm1b_1258', 'feat_esm1b_1262', 'feat_esm1b_1265', 'feat_esm1b_1267', 'feat_esm1b_1268', 'feat_esm1b_1269', 'feat_esm1b_1274', 'feat_esm1b_1275', 'feat_esm1b_1279']\n"
     ]
    }
   ],
   "source": [
    "# get selected features\n",
    "sel_features = X_train_clean.columns[boruta_selector.support_].tolist()\n",
    "\n",
    "# print selected features\n",
    "print(sel_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "276f2524",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "X_train_clean = X_train_clean[sel_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "887566fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1958, 310), (1958,))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_clean.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "066f575f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    1407\n",
       " 1     551\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "99553f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train_clean, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ced9ee65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2814, 310), (2814,))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_resampled.shape, y_train_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2f4ae3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resampled_df = pd.concat([X_train_resampled, y_train_resampled], axis=1)\n",
    "\n",
    "#get the count of each class\n",
    "class_counts = resampled_df['Class'].value_counts()\n",
    "\n",
    "#plot a bar graph\n",
    "plt.bar(class_counts.index, class_counts.values)\n",
    "plt.title('Class distribution after oversampling')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f79f12ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "effc39e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(features, target, model):\n",
    "    train_data, test_data, train_targets, test_targets = train_test_split(features,\n",
    "                                                        target, \n",
    "                                                        test_size=.2,\n",
    "                                                        random_state=42)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    train_data = scaler.fit_transform(train_data)\n",
    "    test_data = scaler.transform(test_data)\n",
    "    \n",
    "    model.fit(train_data, train_targets)\n",
    "    pred = model.predict(test_data)\n",
    "    auc_score = roc_auc_score(test_targets, pred)\n",
    "    print(f\"AUC score: {auc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0c46c617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('classifier',\n",
       "                                        RandomForestClassifier(random_state=42))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'classifier__bootstrap': [True, False],\n",
       "                         'classifier__criterion': ['gini', 'entropy',\n",
       "                                                   'log_loss'],\n",
       "                         'classifier__max_depth': [10, 20, None],\n",
       "                         'classifier__max_features': ['sqrt', 'log2'],\n",
       "                         'classifier__min_samples_leaf': [1, 2, 4],\n",
       "                         'classifier__min_samples_split': [2, 5, 10],\n",
       "                         'classifier__n_estimators': [100, 200, 500]})"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', rf)\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200, 500],\n",
    "    'classifier__max_features': ['sqrt', 'log2'],\n",
    "    'classifier__max_depth': [10, 20, None],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],\n",
    "    'classifier__bootstrap': [True, False],\n",
    "    'classifier__criterion': ['gini', 'entropy', 'log_loss']\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(\n",
    "    pipe, param_grid, cv=5, n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b43e632d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'classifier__bootstrap': False, 'classifier__criterion': 'entropy', 'classifier__max_depth': None, 'classifier__max_features': 'log2', 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 200}\n",
      "Best Score: 0.948478221019829\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "64727ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f0ff6ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__bootstrap': False,\n",
       " 'classifier__criterion': 'entropy',\n",
       " 'classifier__max_depth': None,\n",
       " 'classifier__max_features': 'log2',\n",
       " 'classifier__min_samples_leaf': 2,\n",
       " 'classifier__min_samples_split': 2,\n",
       " 'classifier__n_estimators': 200}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4845b2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score: 0.9146\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=100)\n",
    "evaluate_model(X_train_resampled, y_train_resampled, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ce88d7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_selected = X_test[sel_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9af388d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(490, 310)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0990d662",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3389776f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.739655921093443"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
